{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b711356e-62e9-40d1-90aa-ebd27a189a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795ed03-ddc4-4117-b0c5-afd9e0a97059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_parquet(\"data/model_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63052426-1cf5-4c4c-a685-aa6c3de46ac9",
   "metadata": {},
   "source": [
    "# Proportion d'articles avec des citations\n",
    "Approche :\n",
    "1. On modélise le comportement attendu des journaux, sous l'hypothèse qu'ils respectent la norme de représentativité\n",
    "2. On isole le pouvoir explicatif de ce modèle pour mesurer le poids de cette norme\n",
    "3. On étudie les résidus pour comprendre comment le comportement des journaux s'en écarte\n",
    "\n",
    "On utilise pour cela les résidus relatifs moyens notés $RRM$, qui indiquent la direction et l’ampleur de l’erreur de prédiction en pourcentage de la valeur réelle.\n",
    "\n",
    "$$\\text{RRM} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\hat{y}_i - y_i}{y_i}$$\n",
    "\n",
    "Un $RMM$ positif indique que le modèle surestime la part d’articles contenant des citations, c’est-à-dire qu’il surestime le respect de la norme de représentativité par le journal pour l’alignement politique donné ($\\hat{y}_i ≥ y_i$). Cela signifie que le journal publie moins d’articles avec des citations de cet alignement politique que ce que la norme prévoirait. Pour simplifier la lecture, les valeurs sont inversées dans les tableaux : une valeur positive signale désormais une surreprésentation, et une valeur négative une sous-représentation.\n",
    "\n",
    "*NB1 : Les données sont mensuelles.*\n",
    "\n",
    "***NB2 : Les Verts ne sont pour l'instant pas représentés dans les données.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3902ed0-50b4-4ff9-a298-f00d239f2521",
   "metadata": {},
   "source": [
    "## 1. Modèle de base\n",
    "Les modèles estimés sont de la forme $Y_{i} = \\beta_{i}T_i$ avec :\n",
    "- $Y_{i}$ est la proportion des articles intégrant des citations de la nuance politique $i$ (avec $\\sum_{i=1}^{n} Y_{i} = 1$)\n",
    "- $T_i$ est la proportion des voix obtenue par les candidats de la nuance politique $i$ au premier tour des précédentes élections législatives\n",
    "- $\\beta_{i}$ la pondération globale des résultats électoraux de la nuance politique $i$\n",
    "\n",
    "L'hypothèse implicite est $\\beta_{i} = 1$ : les nuances politiques sont représentées identiquement à leur poids électoral une fois éliminée la couverture de l'action gouvernementale, avec un comportement identique des journaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf0134-8b7d-41d2-83c6-367a6c6bcbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "pvalues = {}\n",
    "\n",
    "for alignement in model_data[\"alignement_politique\"].unique():\n",
    "    subset = model_data[model_data[\"alignement_politique\"] == alignement]\n",
    "\n",
    "    if len(subset) >= 3:\n",
    "        X = subset[[\"votes_share\"]]\n",
    "        y = subset[\"art_share\"]\n",
    "\n",
    "        model = sm.OLS(y, X).fit(cov_type='HC3')\n",
    "        y_pred = model.predict(X)\n",
    "        mean_relative_residual = ((y_pred - y) / y).mean()\n",
    "\n",
    "        results[alignement] = {\n",
    "            \"r_squared\": model.rsquared,\n",
    "            \"mean_residual\": mean_relative_residual}\n",
    "        pvalues[alignement] = model.pvalues.to_dict()\n",
    "\n",
    "    else:\n",
    "        results[alignement] = {\n",
    "            \"r_squared\": None,\n",
    "            \"mean_residual\": None}\n",
    "        pvalues[alignement] = {\n",
    "            \"votes_share\": None,\n",
    "            \"government\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239fc772-79e9-4efe-b053-01b6a7767d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_records = []\n",
    "\n",
    "for alignement, coeffs in pvalues.items():\n",
    "    for coef_name, pval in coeffs.items():\n",
    "        if pval is not None and pval > 0.01:\n",
    "            pval_records.append({\n",
    "                \"alignement\": alignement,\n",
    "                \"coefficient\": coef_name,\n",
    "                \"pvalue\": pval})\n",
    "\n",
    "pval_summary = pd.DataFrame(pval_records)\n",
    "\n",
    "r2_table = pd.DataFrame.from_dict(\n",
    "    {alignement: results[alignement]['r_squared'] for alignement in results},\n",
    "    orient='index',\n",
    "    columns=['r_squared'])\n",
    "\n",
    "bias_table = pd.DataFrame.from_dict(\n",
    "    {alignement: results[alignement]['mean_residual'] for alignement in results},\n",
    "    orient='index',\n",
    "    columns=['mean_residual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba3ca32-a9b1-4bd4-91a6-6d8c6d7f94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pval_summary) == 0:\n",
    "    print(\"No unsignificant coeffs (pval > 0.01)\")\n",
    "else:\n",
    "    print(f\"{len(pval_summary)} unsignificant coeffs (pval > 0.01)\\n\")\n",
    "    print(pval_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b4e95-b205-405a-b4c0-39b795f10bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*r2_table).style.format(\"{:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027640c-d8ad-45f2-a5cb-f37198707db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(-100*bias_table).style.format(\"{:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd14cc-8ce0-4ea6-9704-df79bcf83f30",
   "metadata": {},
   "source": [
    "Le modèle de base fonctionne remarquablement bien pour la droite et la gauche conventionnelle, avec des $R^2$ atteignant 90 % et des résidus relatifs négligeables. Ses performances sont plus ambivalentes pour le centre, avec un $R^2$ encore élevé mais des résidus relatifs très conséquents, signifiant que cette nuance politique fait l'objet de davantage d'articles intégrant des citations que ses résultats électoraux ne le laissent prévoir. Concernant les nuances restantes, le pouvoir explicatif du modèle de base est de 1,5 à 2 fois inférieur, avec des résidus relatifs témoignant d'une sous-représentation dans la presse comparativement à leur poids électoral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e18b37-138c-41d7-94e6-a993a1523570",
   "metadata": {},
   "source": [
    "## 2. Modèle de base + participation au gouvernement\n",
    "Les modèles estimés sont de la forme $Y_{i} = \\alpha_i G_i + \\beta_{i}T_i$ avec :\n",
    "- $Y_{i}$ est la proportion des articles intégrant des citations de la nuance politique $i$ (avec $\\sum_{i=1}^{n} Y_{i} = 1$)\n",
    "- $\\alpha_i$ la prime que les journaux accordent à la nuance politique $i$ lorsqu'elle est au pouvoir, sous la forme d'une fraction fixe des articles intégrant des citations\n",
    "- $G_i$ est une indicatrice valant 1 si le Premier ministre appartient à la nuance politique $i$\n",
    "- $\\beta_{i}$ la pondération globale des résultats électoraux de la nuance politique $i$\n",
    "- $T_i$ est la proportion des voix obtenue par les candidats de la nuance politique $i$ au premier tour des précédentes élections législatives\n",
    "\n",
    "L'hypothèse implicite est $\\alpha_i = \\alpha, \\beta_{i} = \\beta, \\beta = 1 - \\alpha$ : les nuances politiques sont représentées identiquement à leur poids électoral une fois éliminée la couverture de l'action gouvernementale.\n",
    "\n",
    "*NB : il serait intéressant de contraindre $\\alpha_i = \\alpha$, mais cela impliquerait de réécrire totalement le code pour n'estimer plus qu'un unique modèle pour l'ensemble des nuances politiques. Le résultat serait très lourd avec beaucoup d'indicatrices.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13af95-4759-4ecc-aa0a-5b14bde6ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "pvalues = {}\n",
    "\n",
    "for alignement in model_data[\"alignement_politique\"].unique():\n",
    "    subset = model_data[model_data[\"alignement_politique\"] == alignement]\n",
    "\n",
    "    if len(subset) >= 3:\n",
    "        X = subset[[\"votes_share\", \"government\"]]\n",
    "        y = subset[\"art_share\"]\n",
    "\n",
    "        model = sm.OLS(y, X).fit(cov_type='HC3')\n",
    "        y_pred = model.predict(X)\n",
    "        mean_relative_residual = ((y_pred - y) / y).mean()\n",
    "\n",
    "        results[alignement] = {\n",
    "            \"r_squared\": model.rsquared,\n",
    "            \"mean_residual\": mean_relative_residual}\n",
    "        pvalues[alignement] = model.pvalues.to_dict()\n",
    "\n",
    "    else:\n",
    "        results[alignement] = {\n",
    "            \"r_squared\": None,\n",
    "            \"mean_residual\": None}\n",
    "        pvalues[alignement] = {\n",
    "            \"votes_share\": None,\n",
    "            \"government\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67ca02-840c-4c55-8fbc-3fa763906ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_records = []\n",
    "\n",
    "for alignement, coeffs in pvalues.items():\n",
    "    for coef_name, pval in coeffs.items():\n",
    "        if pval is not None and pval > 0.01:\n",
    "            pval_records.append({\n",
    "                \"alignement\": alignement,\n",
    "                \"coefficient\": coef_name,\n",
    "                \"pvalue\": pval})\n",
    "\n",
    "pval_summary = pd.DataFrame(pval_records)\n",
    "\n",
    "r2_table = pd.DataFrame.from_dict(\n",
    "    {alignement: results[alignement]['r_squared'] for alignement in results},\n",
    "    orient='index',\n",
    "    columns=['r_squared'])\n",
    "\n",
    "bias_table = pd.DataFrame.from_dict(\n",
    "    {alignement: results[alignement]['mean_residual'] for alignement in results},\n",
    "    orient='index',\n",
    "    columns=['mean_residual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab0395-f496-4ca9-9f67-9b9b8ccf72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pval_summary) == 0:\n",
    "    print(\"No unsignificant coeffs (pval > 0.01)\")\n",
    "else:\n",
    "    print(f\"{len(pval_summary)} unsignificant coeffs (pval > 0.01)\\n\")\n",
    "    print(pval_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84cf3de-d04a-47f7-919d-6ab07f73eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*r2_table).style.format(\"{:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b73f94d-a867-4957-ad0c-49e64af8ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "(-100*bias_table).style.format(\"{:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a7a53-7c7b-4adb-8572-7f73649a42e2",
   "metadata": {},
   "source": [
    "L'ajout de la participation gouvernementale modifie peu les performances du modèle de base. Cela n'est pas surprenant puisqu'elle concerne seulement les nuances politiques conventionnelles, pour lesquelles ce modèle fonctionne déjà très bien. Son intégration entraîne toutefois une division par presque 3 des résidus relatifs concernant le centre, permettant de les ramener au niveau de l'extrême gauche."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10185798-d336-4d28-8764-6fc0957c773a",
   "metadata": {},
   "source": [
    "## 3. Modèle de base + participation au gouvernement + différences entre journaux\n",
    "Les modèles estimés sont de la forme $Y_{ij} = \\alpha_{ij}G_i + \\beta_{ij}T_i$ avec :\n",
    "- $Y_{ij}$ est la proportion des articles intégrant des citations de la nuance politique $i$ dans le journal $j$ (avec $\\sum_{i=1}^{n} Y_{ij} = 1$)\n",
    "- $\\alpha_{ij}$ la prime que le journal $j$ accorde à la nuance politique $i$ lorsqu'elle est au pouvoir, sous la forme d'une fraction fixe des articles intégrant des citations\n",
    "- $G_i$ est une indicatrice valant 1 si le Premier ministre appartient à la nuance politique $i$\n",
    "- $\\beta_{ij}$ la pondération des résultats électoraux de la nuance politique $i$ par le journal $j$\n",
    "- $T_i$ est la proportion des voix obtenue par les candidats de la nuance politique $i$ au premier tour des précédentes élections législatives\n",
    "\n",
    "L'hypothèse implicite est $\\alpha_{ij} = \\alpha_j, \\beta_{ij} = \\beta_j, \\beta_j = 1 - \\alpha_j$ : les nuances politiques sont représentées identiquement à leur poids électoral une fois éliminée la couverture de l'action gouvernementale. L'importance de celle-ci est la seule différence entre les journaux.\n",
    "\n",
    "*NB : comme précédemment, il serait intéressant d'imposer $\\alpha_{ij} = \\alpha_{j}$ mais cela n'est pas simple.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f64750-9dd5-47bd-9201-9ecb51c3e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "pvalues = {}\n",
    "\n",
    "for alignement in model_data[\"alignement_politique\"].unique():\n",
    "    results[alignement] = {}\n",
    "    pvalues[alignement] = {}\n",
    "    \n",
    "    for journal in model_data[\"journal\"].unique():\n",
    "        subset = model_data[\n",
    "            (model_data[\"alignement_politique\"] == alignement) &\n",
    "            (model_data[\"journal\"] == journal)]\n",
    "        \n",
    "        if len(subset) >= 3:\n",
    "            X = subset[[\"votes_share\", \"government\"]]\n",
    "            y = subset[\"art_share\"]\n",
    "            \n",
    "            model = sm.OLS(y, X).fit(cov_type='HC3')\n",
    "            y_pred = model.predict(X)\n",
    "            mean_relative_residual = ((y_pred - y) / y).mean()\n",
    "            \n",
    "            results[alignement][journal] = {\n",
    "                \"r_squared\": model.rsquared,\n",
    "                \"mean_residual\": mean_relative_residual}\n",
    "            \n",
    "            pvalues[alignement][journal] = model.pvalues.to_dict()\n",
    "            \n",
    "        else:\n",
    "            results[alignement][journal] = {\n",
    "                \"r_squared\": None,\n",
    "                \"mean_residual\": None}\n",
    "            pvalues[alignement][journal] = {\n",
    "                \"votes_share\": None,\n",
    "                \"government\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867cabf-a14e-4cf8-b0c3-eb683c76fcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_records = []\n",
    "\n",
    "for alignement, journals in pvalues.items():\n",
    "    for journal, coeffs in journals.items():\n",
    "        for coef_name, pval in coeffs.items():\n",
    "            if pval is not None and pval > 0.01:\n",
    "                pval_records.append({\n",
    "                    \"alignement\": alignement,\n",
    "                    \"journal\": journal,\n",
    "                    \"coefficient\": coef_name,\n",
    "                    \"pvalue\": pval})\n",
    "\n",
    "pval_summary = pd.DataFrame(pval_records)\n",
    "\n",
    "r2_table = pd.DataFrame({\n",
    "    alignement: {journal: results[alignement][journal]['r_squared'] for journal in results[alignement]}\n",
    "    for alignement in results}).sort_index().T\n",
    "\n",
    "bias_table = pd.DataFrame({\n",
    "    alignement: {journal: results[alignement][journal]['mean_residual'] for journal in results[alignement]}\n",
    "    for alignement in results}).sort_index().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa6919a-4803-4e8b-ae94-70b067ef66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6), sharey=True)\n",
    "\n",
    "sns.heatmap(100*r2_table, annot=True, fmt=\".1f\", cmap=\"RdBu_r\", center=0, ax=axes[0])\n",
    "axes[0].set_title(\"R2 in % by Journal and Political Alignment\")\n",
    "\n",
    "sns.heatmap(-100*bias_table, annot=True, fmt=\".1f\", cmap=\"RdBu_r\", center=0, ax=axes[1])\n",
    "axes[1].set_title(\"Mean Relative Residuals in % by Journal and Political Alignment\")\n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34804fd-1bc4-4458-bd9a-cadf7e52abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pval_summary) == 0:\n",
    "    print(\"No unsignificant coeffs (pval > 0.01)\")\n",
    "else:\n",
    "    print(f\"{len(pval_summary)} unsignificant coeffs (pval > 0.01):\\n\")\n",
    "    print(pval_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d138b8f8-8b81-4cc0-9891-7a7e90dc8b46",
   "metadata": {},
   "source": [
    "Concernant les **nuances politiques conventionnelles**, tous les journaux, à l’exception de *Médiapart*, respectent étroitement la norme de représentativité, avec des valeurs de $R^2$ dépassant 90 %. *Médiapart* suit cette norme dans une moindre mesure, avec des valeurs de $R^2$ allant de 64 % à 83,5 %. Toutefois, le centre est nettement surreprésenté dans *La Croix*, *Le Figaro* et *Le Monde*, mais pas dans *Libération* ni *Médiapart*.\n",
    "\n",
    "Concernant l’**extrême droite**, tous les journaux reflètent sa part de vote de manière similaire, avec des valeurs de $R^2$ situées entre 70 % et 80 %. Elle tend également à être sous-représentée, en particulier par *Médiapart*, *Libération* et, plus encore, *La Croix*.\n",
    "\n",
    "Concernant l’**extrême gauche**, la norme de représentativité semble un peu moins cohérente, avec des valeurs de $R^2$ allant de 58 % à 80 %. Cette nuance politique tend à être sous-représentée par *La Croix* et surreprésentée par *Médiapart*, tandis que les autres journaux semblent plus neutres.\n",
    "\n",
    "Ces résultats sont cohérents avec l’hypothèse de différences dans les lignes éditoriales entre les journaux, mais pas avec l’idée d’un traitement favorable de l’extrême droite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf40f54-63fc-4b4e-8783-78ba7d3f674b",
   "metadata": {},
   "source": [
    "## 4. Modèle de base + participation au gouvernement + différence entre les journaux + effet des périodes\n",
    "Il s'agit maintenant d'étudier plus directement l'hypothèse d'une légitimation de l'extrême droite par la presse écrite nationale. La méthode la plus simple est d'estimer les modèles précédents pour 2 périodes, en écrivant $Y_{ijt} = \\alpha_{ijt}G_it + \\beta_{ijt}T_{it}$ : on s'attend à observer un déclin des $R^2$ associé à une augmentation des $RRM$ pour cette nuance politique.\n",
    "\n",
    "On retient 2012 comme charnière, avec l'idée que...\n",
    "- La période précédente est encore marquée par le jeu fonctionnement traditionnel du système politique, avec une domination persistante de la droite et de la gauche de gouvernement, malgré leurs recompositions.\n",
    "- La période suivante est caractérisée par l'effondrement de ce système, avec l'essort du centre et des extrêmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3eb3a-c05c-48bc-89e8-6e8905b49d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "pvalues = {}\n",
    "cutoff = pd.Period('2012-06', freq='M')\n",
    "\n",
    "for period_label, period_filter in {\n",
    "    'pre2012': model_data[\"month\"] < cutoff,\n",
    "    'post2012': model_data[\"month\"] >= cutoff\n",
    "}.items():\n",
    "    \n",
    "    results[period_label] = {}\n",
    "    pvalues[period_label] = {}\n",
    "\n",
    "    period_data = model_data[period_filter]\n",
    "\n",
    "    for alignement in period_data[\"alignement_politique\"].unique():\n",
    "        results[period_label][alignement] = {}\n",
    "        pvalues[period_label][alignement] = {}\n",
    "\n",
    "        for journal in period_data[\"journal\"].unique():\n",
    "            subset = period_data[\n",
    "                (period_data[\"alignement_politique\"] == alignement) &\n",
    "                (period_data[\"journal\"] == journal)]\n",
    "            \n",
    "            if len(subset) >= 3:\n",
    "                X = subset[[\"votes_share\", \"government\"]]\n",
    "                y = subset[\"art_share\"]\n",
    "                \n",
    "                model = sm.OLS(y, X).fit(cov_type='HC3')\n",
    "                y_pred = model.predict(X)\n",
    "                mean_relative_residual = ((y_pred - y) / y).mean()\n",
    "                \n",
    "                results[period_label][alignement][journal] = {\n",
    "                    \"r_squared\": model.rsquared,\n",
    "                    \"mean_residual\": mean_relative_residual}\n",
    "                \n",
    "                pvalues[period_label][alignement][journal] = model.pvalues.to_dict()\n",
    "\n",
    "            else:\n",
    "                results[period_label][alignement][journal] = {\n",
    "                    \"r_squared\": None,\n",
    "                    \"mean_residual\": None}\n",
    "                pvalues[period_label][alignement][journal] = {\n",
    "                    \"votes_share\": None,\n",
    "                    \"government\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9dc26-4ecb-46a8-8342-c5a525307128",
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_records = []\n",
    "\n",
    "for period, alignements in pvalues.items():\n",
    "    for alignement, journals in alignements.items():\n",
    "        for journal, coeffs in journals.items():\n",
    "            for coef_name, pval in coeffs.items():\n",
    "                if pval is not None and pval > 0.01:\n",
    "                    pval_records.append({\n",
    "                        \"period\": period,\n",
    "                        \"alignement\": alignement,\n",
    "                        \"journal\": journal,\n",
    "                        \"coefficient\": coef_name,\n",
    "                        \"pvalue\": pval})\n",
    "\n",
    "pval_summary = pd.DataFrame(pval_records)\n",
    "\n",
    "r2_tables = {}\n",
    "for period, alignements in results.items():\n",
    "    r2_tables[period] = pd.DataFrame({\n",
    "        alignement: {\n",
    "            journal: results[period][alignement][journal]['r_squared']\n",
    "            for journal in results[period][alignement]\n",
    "        } for alignement in results[period]\n",
    "    }).sort_index().T\n",
    "\n",
    "bias_tables = {}\n",
    "for period, alignements in results.items():\n",
    "    bias_tables[period] = pd.DataFrame({\n",
    "        alignement: {\n",
    "            journal: results[period][alignement][journal]['mean_residual']\n",
    "            for journal in results[period][alignement]\n",
    "        } for alignement in results[period]\n",
    "    }).sort_index().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb7ca5-3022-4b67-af66-93194e5a8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(pval_summary) == 0:\n",
    "    print(\"No unsignificant coeffs (pval > 0.01)\")\n",
    "else:\n",
    "    print(f\"{len(pval_summary)} unsignificant coeffs (pval > 0.01):\\n\")\n",
    "    print(pval_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c792d1-f414-4708-9d20-683b69fa37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12), sharex=True, sharey=True)\n",
    "\n",
    "sns.heatmap(100 * r2_tables[\"pre2012\"], annot=True, fmt=\".1f\", cmap=\"RdBu_r\", center=0, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"R² (%) — Pre-2012\")\n",
    "\n",
    "sns.heatmap(100 * r2_tables[\"post2012\"], annot=True, fmt=\".1f\", cmap=\"RdBu_r\", center=0, ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"R² (%) — Post-2012\")\n",
    "\n",
    "sns.heatmap(-100 * bias_tables[\"pre2012\"], annot=True, fmt=\".1f\", cmap=\"RdBu_r\", center=0, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Bias (%) — Pre-2012\")\n",
    "\n",
    "sns.heatmap(-100 * bias_tables[\"post2012\"], annot=True, fmt=\".1f\", cmap=\"RdBu_r\", center=0, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Bias (%) — Post-2012\")\n",
    "\n",
    "axes[0, 1].set_ylabel(\"\")\n",
    "axes[1, 1].set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd292aa-c877-4f5b-9a19-f5d1c2949c46",
   "metadata": {},
   "source": [
    "Très rapidement, c'est l'extrême gauche qui semble bénéficier d'un traitement de faveur plutôt que l'extrême droite !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b7078-fef5-45b9-888d-bd8507012658",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "Le nombre d’articles intégrant des citations pourrait en fait dépendre de la répartition des sièges à l’Assemblée nationale, qui serait mieux reflétée par les scores électoraux des partis dominants. Il est aussi possible que la couverture médiatique des extrêmes soit davantage sensible aux cycles électoraux et aux scores anticipés à l'élection présidentielle. **Dans l'immédiat, il faudrait surtout intégrer les Verts !**\n",
    "\n",
    "On pourrait tester plus formellement des hypothèses en bootstrappant..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
