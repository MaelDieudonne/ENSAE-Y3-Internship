{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f01ac-0bed-4316-a938-35e7f77a7c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.lines import Line2D\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import root_mean_squared_error as root_mse\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2239d4f3-0bac-45ed-94c5-a9b256918be7",
   "metadata": {},
   "source": [
    "# Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48aea2-8a13-420b-aef1-db7aabf4a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = pd.read_parquet(\"data/model_data_mentions_njl.parquet\")\n",
    "quotes = pd.read_parquet(\"data/model_data_njl.parquet\")\n",
    "\n",
    "model_data = pd.read_parquet(\"data/model_data_mentions.parquet\")\n",
    "model_data_no_journal = pd.read_parquet(\"data/model_data_mentions_njl.parquet\")\n",
    "nuances_order = [\"Far right\", \"Right\", \"Center\", \"Left\", \"Far left\", \"Other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a140f-5111-434d-ab77-95e8de9163f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "presi_dates = [\n",
    "    \"26/04/1981\", \"10/05/1981\",\n",
    "    \"24/04/1988\", \"08/05/1988\",\n",
    "    \"23/04/1995\", \"07/05/1995\",\n",
    "    \"21/04/2002\", \"05/05/2002\",\n",
    "    \"22/04/2007\", \"06/05/2007\",\n",
    "    \"22/04/2012\", \"06/05/2012\",\n",
    "    \"21/04/2017\", \"07/05/2017\",\n",
    "    \"10/04/2022\", \"24/04/2022\"]\n",
    "presi_months = pd.to_datetime(presi_dates, dayfirst=True).to_period('M').drop_duplicates()\n",
    "\n",
    "legi_dates = [\n",
    "    \"14/06/1981\", \"21/06/1981\",\n",
    "    \"16/03/1986\",\n",
    "    \"05/06/1988\", \"11/06/1988\",\n",
    "    \"21/03/1993\", \"28/03/1993\",\n",
    "    \"25/05/1997\", \"01/06/1997\",\n",
    "    \"09/06/2002\", \"16/06/2002\",\n",
    "    \"10/06/2007\", \"17/06/2007\",\n",
    "    \"10/06/2012\", \"17/06/2012\",\n",
    "    \"11/06/2017\", \"18/06/2017\",\n",
    "    \"12/06/2022\", \"19/06/2022\",\n",
    "    \"29/06/2024\", \"06/07/2024\"]\n",
    "legi_months = pd.to_datetime(legi_dates, dayfirst=True).to_period('M').drop_duplicates()\n",
    "\n",
    "europ_dates = [\n",
    "    \"17/06/1984\",\n",
    "    \"18/06/1989\",\n",
    "    \"12/06/1994\",\n",
    "    \"13/06/1999\",\n",
    "    \"13/06/2004\",\n",
    "    \"07/06/2009\",\n",
    "    \"25/05/2014\",\n",
    "    \"26/05/2019\",\n",
    "    \"09/06/2024\"]\n",
    "europ_months = pd.to_datetime(europ_dates, dayfirst=True).to_period('M').drop_duplicates()\n",
    "\n",
    "main_elec_dates = presi_dates + legi_dates + europ_dates\n",
    "main_elec_months = pd.to_datetime(main_elec_dates, dayfirst=True).to_period('M').drop_duplicates().sort_values()\n",
    "\n",
    "def add_shaded_periods(ax_list, periods, color, alpha):\n",
    "    start_period = None\n",
    "    for i, period in enumerate(periods):\n",
    "        if start_period is None:\n",
    "            start_period = period\n",
    "        is_last = (i == len(periods) - 1)\n",
    "        is_gap = (not is_last and periods[i + 1] != period + 1)\n",
    "        if is_last or is_gap:\n",
    "            end_period = period\n",
    "            start = start_period.to_timestamp()\n",
    "            end = (end_period + MonthEnd(1)).to_timestamp()\n",
    "            for ax in ax_list:\n",
    "                ax.axvspan(start, end, color=color, alpha=alpha)\n",
    "            start_period = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb8e26a-8690-46a2-8dc4-4fc5bf59f509",
   "metadata": {},
   "source": [
    "# Corrélation avec les quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787a38e-ed24-4931-bc13-aa5c2b4d07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = mentions[['month', 'political_alignment', 'quotes_share']]\n",
    "quotes = quotes[['month', 'political_alignment', 'quotes_share']]\n",
    "all_data = pd.merge(mentions, quotes, on=['month', 'political_alignment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69ab22-5e9a-4032-b915-514cbbe52383",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = all_data['quotes_share_x'].corr(all_data['quotes_share_y'])\n",
    "print(f\"{correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af64a9-b2ee-43c6-8070-e0f2dff9d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data[['quotes_share_x']]\n",
    "y = all_data['quotes_share_y']\n",
    "\n",
    "model = LinearRegression().fit(X, y)\n",
    "print(f\"R²: {model.score(X, y)}\")\n",
    "print(f\"Intercept: {model.intercept_}, Slope: {model.coef_[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4494252-3383-4e62-80b5-fabefc2b2d52",
   "metadata": {},
   "source": [
    "# Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f720d4-20af-4faa-b263-487a7e04cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = \"quotes_share\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa872948-bad5-4015-a66b-61176142fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_y_pred(\n",
    "    df,\n",
    "    n, alpha, beta, gamma, theta,\n",
    "    delta_pre_5, delta_pre_4, delta_pre_3, delta_pre_2, delta_pre_1, delta_pre_0,\n",
    "    lambda_1, lambda_2):\n",
    "    \n",
    "    baseline = (\n",
    "        beta * (1 - n * alpha - theta) * df[\"na_share\"] +\n",
    "        gamma * (1 - n * alpha - theta) * df[\"pres_votes_share\"] +\n",
    "        theta * df[\"government\"])\n",
    "\n",
    "    y_pred = (\n",
    "        alpha +\n",
    "        df[\"inter_dum\"] * baseline +\n",
    "        df[\"pre_5\"] * (delta_pre_5 * baseline + (1 - delta_pre_5) * df[\"pres_poll_result\"]) +\n",
    "        df[\"pre_4\"] * (delta_pre_4 * baseline + (1 - delta_pre_4) * df[\"pres_poll_result\"]) +\n",
    "        df[\"pre_3\"] * (delta_pre_3 * baseline + (1 - delta_pre_3) * df[\"pres_poll_result\"]) +\n",
    "        df[\"pre_2\"] * (delta_pre_2 * baseline + (1 - delta_pre_2) * df[\"pres_poll_result\"]) +\n",
    "        df[\"pre_1\"] * (delta_pre_1 * baseline + (1 - delta_pre_1) * df[\"pres_poll_result\"]) +\n",
    "        df[\"pre_0\"] * (delta_pre_0 * baseline + (1 - delta_pre_0) * df[\"pres_poll_result\"]) +\n",
    "        df[\"post_dum\"] * (\n",
    "            (1 - n * alpha - lambda_1 - lambda_2) * df[\"pres_votes_share\"] +\n",
    "            lambda_1 * df[\"r2_rank_1\"] +\n",
    "            lambda_2 * df[\"r2_rank_2\"]))\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1844cf-8a2b-4570-b809-c953b47aeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, data_opt, y_opt):\n",
    "    alpha = params[0]\n",
    "    beta = params[1]\n",
    "    gamma = 1 - beta\n",
    "    theta = params[2]\n",
    "    delta_pre_5, delta_pre_4, delta_pre_3, delta_pre_2, delta_pre_1, delta_pre_0 = params[3:9]\n",
    "    lambda_1, lambda_2 = params[9:11]\n",
    "\n",
    "    y_pred = compute_y_pred(\n",
    "        data_opt,\n",
    "        n, alpha, beta, gamma, theta,\n",
    "        delta_pre_5, delta_pre_4, delta_pre_3, delta_pre_2, delta_pre_1, delta_pre_0,\n",
    "        lambda_1, lambda_2)\n",
    "\n",
    "    return root_mse(y_opt, y_pred)\n",
    "\n",
    "# Initial guess for the coefficients: alpha, beta, theta, delta_pre_5 to delta_pre_0, lambda_1 and lambda_2\n",
    "initial_guess = [0.01, 0.7, 0.2, 0.9, 0.85, 0.8, 0.7, 0.5, 0.2, 0.15, 0.1]\n",
    "\n",
    "# Bounds: all coefficients between 0 and 1\n",
    "bounds = [(0, 1)] * 11\n",
    "\n",
    "# Constraints: increasing poll weights during electoral campaigns\n",
    "constraints = [\n",
    "    {\"type\": \"ineq\", \"fun\": lambda x: x[3] - x[4]},  # delta_pre_5 > delta_pre_4\n",
    "    {\"type\": \"ineq\", \"fun\": lambda x: x[4] - x[5]},  # delta_pre_4 > delta_pre_3\n",
    "    {\"type\": \"ineq\", \"fun\": lambda x: x[5] - x[6]},  # delta_pre_3 > delta_pre_2\n",
    "    {\"type\": \"ineq\", \"fun\": lambda x: x[6] - x[7]},  # delta_pre_2 > delta_pre_1\n",
    "    {\"type\": \"ineq\", \"fun\": lambda x: x[7] - x[8]},  # delta_pre_1 > delta_pre_0\n",
    "]\n",
    "\n",
    "# Number of political nuances\n",
    "n = len(model_data_no_journal['political_alignment'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea1a55-6828-4578-9fba-6b2774b10237",
   "metadata": {},
   "source": [
    "### Sur l'ensemble des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432316cf-3f8e-4c2b-be86-cfc42f76e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_opt = model_data_no_journal[\n",
    "    [\"inter_dum\", \"pre_5\", \"pre_4\", \"pre_3\", \"pre_2\", \"pre_1\", \"pre_0\", \"post_dum\", \n",
    "     \"na_share\", \"pres_votes_share\", \"government\", \"pres_poll_result\", \"r2_rank_1\", \"r2_rank_2\"]]\n",
    "\n",
    "y_opt = model_data_no_journal[outcome]\n",
    "\n",
    "result = minimize(objective, initial_guess, args=(data_opt, y_opt), bounds=bounds, constraints=[], method='SLSQP')\n",
    "# result = minimize(objective, initial_guess, args=(data_opt, y_opt), bounds=bounds, constraints=constraints, method='SLSQP')\n",
    "\n",
    "if result.success:\n",
    "    alpha, beta, theta, delta_pre_5, delta_pre_4, delta_pre_3, delta_pre_2, delta_pre_1, delta_pre_0, lambda_1, lambda_2 = result.x\n",
    "    gamma = 1 - beta\n",
    "\n",
    "    print(f\"Optimal alpha: {alpha:.5f}\")\n",
    "    print(f\"Optimal beta: {beta:.5f}\")\n",
    "    print(f\"Optimal gamma: {gamma:.5f}\")\n",
    "    print(f\"Optimal theta: {theta:.5f}\")\n",
    "    print(f\"Optimal delta_pre_5: {delta_pre_5:.5f}\")\n",
    "    print(f\"Optimal delta_pre_4: {delta_pre_4:.5f}\")\n",
    "    print(f\"Optimal delta_pre_3: {delta_pre_3:.5f}\")\n",
    "    print(f\"Optimal delta_pre_2: {delta_pre_2:.5f}\")\n",
    "    print(f\"Optimal delta_pre_1: {delta_pre_1:.5f}\")\n",
    "    print(f\"Optimal delta_pre_0: {delta_pre_0:.5f}\")\n",
    "    print(f\"Optimal lambda_1: {lambda_1:.5f}\")\n",
    "    print(f\"Optimal lambda_2: {lambda_2:.5f}\")\n",
    "else:\n",
    "    print(\"Optimization failed:\", result.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbd3b3-df70-4140-b4dc-d81b9566a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = compute_y_pred(\n",
    "    data_opt,\n",
    "    n, alpha, beta, gamma, theta,\n",
    "    delta_pre_5, delta_pre_4, delta_pre_3, delta_pre_2, delta_pre_1, delta_pre_0,\n",
    "    lambda_1, lambda_2)\n",
    "\n",
    "r2 = r2_score(y_opt, y_pred)\n",
    "mr = (y_opt - y_pred).mean()\n",
    "rmspe = root_mse(y_opt, y_pred)\n",
    "\n",
    "print(f\"R2: {100*r2:.3f}%\")\n",
    "print(f\"MR: {100*mr:.5f}%\")\n",
    "print(f\"RMSPE: {rmspe:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e91850-fc74-4bfb-8a2f-111fd017f3b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bootstrapping (on months instead of observations to respect compositionnality)\n",
    "n_bootstraps = 5000\n",
    "n_blocks = len(model_data_no_journal) // 6\n",
    "\n",
    "def run_bootstrap_iteration(seed):\n",
    "    np.random.seed(seed)\n",
    "    sampled_block_ids = np.random.choice(n_blocks, size=n_blocks, replace=True)\n",
    "    sampled_row_indices = np.concatenate([\n",
    "        np.arange(block_id * 6, block_id * 6 + 6) for block_id in sampled_block_ids\n",
    "    ])\n",
    "    boot_data = model_data_no_journal.iloc[sampled_row_indices].reset_index(drop=True)\n",
    "    boot_data = boot_data[[\n",
    "        outcome,\n",
    "        \"political_alignment\", \"inter_dum\", \"pre_5\", \"pre_4\", \"pre_3\", \"pre_2\", \"pre_1\", \"pre_0\", \"post_dum\",\n",
    "        \"na_share\", \"pres_votes_share\", \"government\", \"pres_poll_result\", \"r2_rank_1\", \"r2_rank_2\"]]\n",
    "    boot_y = boot_data[outcome]\n",
    "\n",
    "    result = minimize(objective, initial_guess, args=(boot_data, boot_y), bounds=bounds, constraints=[], method='SLSQP')\n",
    "    \n",
    "    if result.success:\n",
    "        alpha_bst, beta_bst, theta_bst, delta_pre_5_bst, delta_pre_4_bst, delta_pre_3_bst, delta_pre_2_bst, delta_pre_1_bst, delta_pre_0_bst, lambda_1_bst, lambda_2_bst = result.x\n",
    "        gamma_bst = 1 - beta_bst\n",
    "        return {\n",
    "            \"alpha\": alpha_bst,\n",
    "            \"beta\": beta_bst,\n",
    "            \"gamma\": gamma_bst,\n",
    "            \"theta\": theta_bst,\n",
    "            \"delta_pre_5\": delta_pre_5_bst,\n",
    "            \"delta_pre_4\": delta_pre_4_bst,\n",
    "            \"delta_pre_3\": delta_pre_3_bst,\n",
    "            \"delta_pre_2\": delta_pre_2_bst,\n",
    "            \"delta_pre_1\": delta_pre_1_bst,\n",
    "            \"delta_pre_0\": delta_pre_0_bst,\n",
    "            \"lambda_1\": lambda_1_bst,\n",
    "            \"lambda_2\": lambda_2_bst\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(run_bootstrap_iteration)(seed)\n",
    "    for seed in tqdm(range(n_bootstraps), desc=\"Bootstrapping\")\n",
    ")\n",
    "\n",
    "# Filter out failed runs (None)\n",
    "bootstrap_results = [r for r in results if r is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89cb53-9b45-4588-9bdd-551577688a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a one-tail approach for pvalues as coefficients are bounded by zero\n",
    "bootstrap_df = pd.DataFrame(bootstrap_results)\n",
    "pval = (bootstrap_df <= 0).sum() / len(bootstrap_df)\n",
    "original_coeffs = pd.Series({\n",
    "    \"alpha\": alpha,\n",
    "    \"beta\": beta,\n",
    "    \"gamma\": gamma,\n",
    "    \"theta\": theta,\n",
    "    \"delta_pre_5\": delta_pre_5,\n",
    "    \"delta_pre_4\": delta_pre_4,\n",
    "    \"delta_pre_3\": delta_pre_3,\n",
    "    \"delta_pre_2\": delta_pre_2,\n",
    "    \"delta_pre_1\": delta_pre_1,\n",
    "    \"delta_pre_0\": delta_pre_0,\n",
    "    \"lambda_1\": lambda_1,\n",
    "    \"lambda_2\": lambda_2})\n",
    "\n",
    "\n",
    "bootstrap_df = bootstrap_df.describe(percentiles=[0.025, 0.5, 0.975]).T\n",
    "bootstrap_df[\"pval\"] = pval\n",
    "bootstrap_df[\"coeff\"] = original_coeffs\n",
    "bootstrap_df = bootstrap_df.drop(columns = ['count', 'min', '50%', 'max'])\n",
    "cols = [\"coeff\"] + [col for col in bootstrap_df.columns if col != \"coeff\"]\n",
    "bootstrap_df = bootstrap_df[cols]\n",
    "bootstrap_df.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6731713-8e9c-408a-a386-274b3aa198d0",
   "metadata": {},
   "source": [
    "### Pour la droite et la gauche dans *Le Monde* avant juin 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724f7d6-aca9-4ebd-91b8-06fd0a4ef9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping n=6 for consistent results\n",
    "cutoff = pd.Period('2012-06', freq='M')\n",
    "\n",
    "data_opt = model_data[\n",
    "    (model_data[\"month\"] <= cutoff) & \n",
    "    (model_data[\"journal\"] == \"Le Monde\") &\n",
    "    (model_data[\"political_alignment\"].isin(['Right', 'Left']))\n",
    "    ][[\"inter_dum\", \"pre_5\", \"pre_4\", \"pre_3\", \"pre_2\", \"pre_1\", \"pre_0\", \"post_dum\", \n",
    "       \"na_share\", \"pres_votes_share\", \"government\", \"pres_poll_result\", \"r2_rank_1\", \"r2_rank_2\"]]\n",
    "\n",
    "y_opt = model_data[\n",
    "    (model_data[\"month\"] <= cutoff) & \n",
    "    (model_data[\"journal\"] == \"Le Monde\") &\n",
    "    (model_data[\"political_alignment\"].isin(['Right', 'Left']))\n",
    "    ][outcome]\n",
    "\n",
    "result = minimize(objective, initial_guess, args=(data_opt, y_opt), bounds=bounds, constraints=[], method='SLSQP')\n",
    "# result = minimize(objective, initial_guess, args=(data_opt, y_opt), bounds=bounds, constraints=constraints, method='SLSQP')\n",
    "\n",
    "if result.success:\n",
    "    alpha_loc, beta_loc, theta_loc, delta_pre_5_loc, delta_pre_4_loc, delta_pre_3_loc, delta_pre_2_loc, delta_pre_1_loc, delta_pre_0_loc, lambda_1_loc, lambda_2_loc = result.x\n",
    "    gamma_loc = 1 - beta_loc\n",
    "\n",
    "    print(f\"Optimal alpha: {alpha_loc:.5f}\")\n",
    "    print(f\"Optimal beta: {beta_loc:.5f}\")\n",
    "    print(f\"Optimal gamma: {gamma_loc:.5f}\")\n",
    "    print(f\"Optimal theta: {theta_loc:.5f}\")\n",
    "    print(f\"Optimal delta_pre_5: {delta_pre_5_loc:.5f}\")\n",
    "    print(f\"Optimal delta_pre_4: {delta_pre_4_loc:.5f}\")\n",
    "    print(f\"Optimal delta_pre_3: {delta_pre_3_loc:.5f}\")\n",
    "    print(f\"Optimal delta_pre_2: {delta_pre_2_loc:.5f}\")\n",
    "    print(f\"Optimal delta_pre_1: {delta_pre_1_loc:.5f}\")\n",
    "    print(f\"Optimal delta_pre_0: {delta_pre_0_loc:.5f}\")\n",
    "    print(f\"Optimal lambda_1: {lambda_1_loc:.5f}\")\n",
    "    print(f\"Optimal lambda_2: {lambda_2_loc:.5f}\")\n",
    "else:\n",
    "    print(\"Optimization failed:\", result.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76f18d-eab7-4545-8dbd-0a34ee283ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on restricted dataset\n",
    "y_pred = compute_y_pred(\n",
    "    data_opt,\n",
    "    n, alpha_loc, beta_loc, gamma_loc, theta_loc,\n",
    "    delta_pre_5_loc, delta_pre_4_loc, delta_pre_3_loc, delta_pre_2_loc, delta_pre_1_loc, delta_pre_0_loc,\n",
    "    lambda_1_loc, lambda_2_loc)\n",
    "\n",
    "r2 = r2_score(y_opt, y_pred)\n",
    "mr = (y_opt - y_pred).mean()\n",
    "rmspe = root_mse(y_opt, y_pred)\n",
    "\n",
    "print(f\"R2: {100*r2:.3f}%\")\n",
    "print(f\"MR: {100*mr:.5f}%\")\n",
    "print(f\"RMSPE: {rmspe:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1323ba-9b4f-4a00-b1a9-34bf8b34e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on full dataset\n",
    "y_pred = compute_y_pred(\n",
    "    model_data_no_journal,\n",
    "    n, alpha_loc, beta_loc, gamma_loc, theta_loc,\n",
    "    delta_pre_5_loc, delta_pre_4_loc, delta_pre_3_loc, delta_pre_2_loc, delta_pre_1_loc, delta_pre_0_loc,\n",
    "    lambda_1_loc, lambda_2_loc)\n",
    "\n",
    "y_opt = model_data_no_journal[outcome]\n",
    "\n",
    "r2 = r2_score(y_opt, y_pred)\n",
    "mr = (y_opt - y_pred).mean()\n",
    "rmspe = root_mse(y_opt, y_pred)\n",
    "\n",
    "print(f\"R2: {100*r2:.3f}%\")\n",
    "print(f\"MR: {100*mr:.5f}%\")\n",
    "print(f\"RMSPE: {rmspe:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f47a4-4abe-46e7-bb67-f3045b12bdb7",
   "metadata": {},
   "source": [
    "# 2. Ecarts à la norme de représentativité selon les nuances politiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3809e-3ba5-48d1-b377-de438df09429",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_no_journal['y_norm'] = compute_y_pred(\n",
    "    model_data_no_journal,\n",
    "    n, alpha, beta, gamma, theta,\n",
    "    delta_pre_5, delta_pre_4, delta_pre_3, delta_pre_2, delta_pre_1, delta_pre_0,\n",
    "    lambda_1, lambda_2)\n",
    "plot_data = model_data_no_journal.copy()\n",
    "plot_data['abs_residuals'] = 100 * (plot_data[outcome] - plot_data['y_norm'])\n",
    "plot_data['month'] = plot_data['month'].dt.to_timestamp()\n",
    "\n",
    "alignment_groups = [\n",
    "    (['Far left', 'Far right', 'Other'],\n",
    "     {'Far left': 'crimson',\n",
    "      'Far right': 'royalblue',\n",
    "      'Other': 'forestgreen'}),\n",
    "    (['Right', 'Left', 'Center'],\n",
    "     {'Right': 'cornflowerblue',\n",
    "      'Left': 'orchid',\n",
    "      'Center': 'goldenrod'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3556c-0c89-4fbb-8c50-5948365c293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alignment in ['Far right', 'Far left']:\n",
    "    color = 'royalblue' if alignment == 'Far right' else 'crimson'\n",
    "    subset_data = plot_data[plot_data['political_alignment'] == alignment].copy()\n",
    "    subset_data['MA_observed'] = subset_data[outcome].rolling(window=3).mean()\n",
    "    subset_data['MA_abs'] = subset_data['abs_residuals'].rolling(window=3).mean()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(24, 4))\n",
    "\n",
    "    sns.lineplot(data=subset_data, x='month', y=outcome, ax=ax, label='Observed values', alpha=0.15, color=color, linestyle='-')\n",
    "    sns.lineplot(data=subset_data, x='month', y='MA_observed', ax=ax, label='12 months moving average for OV', color=color, linestyle='dashdot')\n",
    "    sns.lineplot(data=subset_data, x='month', y='y_norm', ax=ax, label='Predicted values', color='teal', linestyle='dotted')\n",
    "    ax.set_title(\"Observed and Predicted Values\")\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    add_shaded_periods([ax], main_elec_months, color='black', alpha=0.1)\n",
    "\n",
    "    plt.suptitle(f\"Proportion of Mentions Attributed to {alignment} Politicians\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"output/{alignment}_mention_graph.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f8652-b99f-4424-98c5-42ab1719a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(24, 16), sharex=True)\n",
    "\n",
    "for ax, (political_alignments, colors) in zip(axes, alignment_groups):\n",
    "    alignment_handles = []\n",
    "\n",
    "    for alignment in political_alignments:\n",
    "        subset_data = plot_data[plot_data['political_alignment'] == alignment].copy()\n",
    "        subset_data['MA'] = subset_data[outcome].rolling(window=4).mean()\n",
    "        \n",
    "        ax.plot(subset_data['month'], subset_data[outcome], label=None,\n",
    "                alpha=0.3, color=colors[alignment], linestyle='-')\n",
    "        ax.plot(subset_data['month'], subset_data['MA'], label=None,\n",
    "                alpha=0.65, color=colors[alignment], linestyle='dashdot')\n",
    "        ax.plot(subset_data['month'], subset_data['y_norm'], label=None,\n",
    "                alpha=1, color=colors[alignment], linestyle='dotted')\n",
    "        \n",
    "        alignment_handles.append(Line2D([0], [0], color=colors[alignment], lw=2, label=alignment))\n",
    "\n",
    "    alignment_legend = ax.legend(handles=alignment_handles, title=\"Political alignment\", loc=\"upper left\")\n",
    "    ax.add_artist(alignment_legend)\n",
    "\n",
    "    line_type_handles = [\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='-', label=\"Monthly average\"),\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='dashdot', label=\"6 months moving average\"),\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='dotted', label=\"Predictions\")]\n",
    "    ax.legend(handles=line_type_handles, title=\"Values\", loc=\"upper right\")\n",
    "\n",
    "axes[-1].set_xlabel(\"\")\n",
    "\n",
    "add_shaded_periods(axes, main_elec_months, color='black', alpha=0.1)\n",
    "\n",
    "plt.suptitle(\"Mentions Distribution by Political Affiliation\\nObserved vs. Predicted Values\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/nuances_mentions_val_graph.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac606c34-6e6a-421e-a7bf-ea1a8c3725e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(24, 12), sharex=True)\n",
    "\n",
    "for ax, (political_alignments, colors) in zip(axes, alignment_groups):\n",
    "    alignment_handles = []\n",
    "\n",
    "    for alignment in political_alignments:\n",
    "        subset_data = plot_data[plot_data['political_alignment'] == alignment].copy()\n",
    "        subset_data['MA'] = subset_data['abs_residuals'].rolling(window=6).mean()\n",
    "        \n",
    "        ax.plot(subset_data['month'], subset_data['abs_residuals'], label=None,\n",
    "                alpha=0.2, color=colors[alignment], linestyle='-')\n",
    "        ax.plot(subset_data['month'], subset_data['MA'], label=None,\n",
    "                alpha=0.65, color=colors[alignment], linestyle='-.')\n",
    "        ax.plot(subset_data['month'], [0] * len(subset_data), label=None,\n",
    "                alpha=1, color='darkgray', linestyle=':')\n",
    "        \n",
    "        alignment_handles.append(Line2D([0], [0], color=colors[alignment], lw=2, label=alignment))\n",
    "\n",
    "    alignment_legend = ax.legend(handles=alignment_handles, title=\"Political alignment\", loc=\"upper left\")\n",
    "    ax.add_artist(alignment_legend)\n",
    "\n",
    "    line_type_handles = [\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='-', label=\"Monthly average\"),\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='-.', label=\"6 months moving average\"),\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle=':', label=\"Predictions\")\n",
    "    ]\n",
    "    ax.legend(handles=line_type_handles, title=\"Values\", loc=\"upper right\")\n",
    "\n",
    "axes[-1].set_xlabel(\"\")\n",
    "\n",
    "add_shaded_periods(axes, main_elec_months, color='black', alpha=0.1)\n",
    "\n",
    "plt.suptitle(\"Mentions Distribution by Political Affiliation\\nAbsolute Residuals (%)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/nuances_mentions_abs_graph.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5a0a09-38bc-4400-a9e9-9606b82990b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_proportional_metrics(y_norm, y_true):\n",
    "    y_norm = np.array(y_norm)\n",
    "    y_true = np.array(y_true)\n",
    "    \n",
    "    # Initialize arrays\n",
    "    TP = np.zeros_like(y_norm)\n",
    "    TN = np.zeros_like(y_norm)\n",
    "    FP = np.zeros_like(y_norm)\n",
    "    FN = np.zeros_like(y_norm)\n",
    "    \n",
    "    # Calculate difference\n",
    "    diff = y_norm - y_true\n",
    "    \n",
    "    # Case 1: y_norm - y_true = 0 (perfect prediction)\n",
    "    perfect_mask = (diff == 0)\n",
    "    TP[perfect_mask] = 1\n",
    "    FP[perfect_mask] = 0\n",
    "    FN[perfect_mask] = 0\n",
    "    \n",
    "    # Case 2: y_norm - y_true > 0 (over-prediction)\n",
    "    over_mask = (diff > 0)\n",
    "    TP[over_mask] = y_true[over_mask] / y_norm[over_mask]\n",
    "    FP[over_mask] = diff[over_mask] / y_norm[over_mask]\n",
    "    FN[over_mask] = 0\n",
    "    \n",
    "    # Case 3: y_norm - y_true < 0 (under-prediction)\n",
    "    under_mask = (diff < 0)\n",
    "    TP[under_mask] = 1\n",
    "    FN[under_mask] = - diff[under_mask] / y_true[under_mask]\n",
    "    FP[under_mask] = 0\n",
    "    \n",
    "    return {\n",
    "        'TP': TP.mean(),\n",
    "        'FP': FP.mean(),\n",
    "        'FN': FN.mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a19134-effc-4eb5-a88e-eb66431ad04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff1 = pd.Period('2002-06', freq='M')\n",
    "cutoff2 = pd.Period('2017-06', freq='M')\n",
    "\n",
    "results = []\n",
    "\n",
    "for period_label, period_filter in {\n",
    "    '1981-2002': model_data_no_journal[\"month\"] < cutoff1,\n",
    "    '2002-2017': (model_data_no_journal[\"month\"] >= cutoff1) & (model_data_no_journal[\"month\"] < cutoff2),\n",
    "    '2017-2024': model_data_no_journal[\"month\"] >= cutoff2\n",
    "}.items():\n",
    "    period_data = model_data_no_journal[period_filter]\n",
    "    \n",
    "    for alignment in period_data[\"political_alignment\"].unique():\n",
    "\n",
    "        subset_data = period_data[period_data[\"political_alignment\"] == alignment]\n",
    "        y = subset_data[outcome]\n",
    "        y_norm = subset_data['y_norm']\n",
    "        metrics = compute_proportional_metrics(y_norm, y)\n",
    "        results.append({\n",
    "            'period': period_label,\n",
    "            'alignment': alignment,\n",
    "            '% correct predictions': 100 * metrics['TP'],\n",
    "            '% excess predictions': 100 * metrics['FP'],\n",
    "            '% missing predictions': 100 * metrics['FN']})\n",
    "\n",
    "summary = pd.DataFrame(results)\n",
    "summary[\"alignment\"] = pd.Categorical(summary[\"alignment\"], categories=nuances_order, ordered=True)\n",
    "summary = summary.pivot_table(index=\"alignment\",\n",
    "                                    columns=\"period\",\n",
    "                                    values=[\"% correct predictions\",\n",
    "                                            \"% excess predictions\",\n",
    "                                            \"% missing predictions\"],\n",
    "                                    observed=False)\n",
    "summary = summary.reset_index()\n",
    "summary.columns.names = [None, None]\n",
    "summary.style.hide(axis=\"index\").format({col: \"{:.3f}\" for col in summary.columns[1:]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d2dfa-8ce0-4880-b0a0-b88660995b2f",
   "metadata": {},
   "source": [
    "# 2. Ecarts à la norme de représentativité selon les journaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa4506-a390-4b76-9e00-c7a126320ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data['y_norm'] = compute_y_pred(\n",
    "    model_data,\n",
    "    n, alpha, beta, gamma, theta,\n",
    "    delta_pre_5, delta_pre_4, delta_pre_3, delta_pre_2, delta_pre_1, delta_pre_0,\n",
    "    lambda_1, lambda_2)\n",
    "plot_data = model_data.copy()\n",
    "plot_data['abs_residuals'] = 100 * (plot_data[outcome] - plot_data['y_norm'])\n",
    "plot_data['month'] = plot_data['month'].dt.to_timestamp()\n",
    "\n",
    "colors = {\n",
    "    'Le Figaro': 'goldenrod',\n",
    "    'Libération': 'limegreen',\n",
    "    'Le Monde': 'orchid',\n",
    "    'La Croix': 'skyblue',\n",
    "    'Médiapart': 'crimson'}\n",
    "\n",
    "alignments = [\n",
    "    \"Far right\",\n",
    "    \"Right\",\n",
    "    \"Center\",\n",
    "    \"Left\",\n",
    "    \"Far left\"]\n",
    "\n",
    "n_alignments = len(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7479b96-184e-4ed0-9528-39c29b3767a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(n_alignments, 1, figsize=(24, 4 * n_alignments), sharex=True)\n",
    "\n",
    "for i, alignment in enumerate(alignments):\n",
    "    ax = axes[i]\n",
    "    subset_data = plot_data[plot_data['political_alignment'] == alignment]\n",
    "\n",
    "    for journal in subset_data['journal'].unique():\n",
    "        if journal == 'Médiapart': continue\n",
    "        sub_subset_data = subset_data[subset_data['journal'] == journal].copy()\n",
    "        sub_subset_data['MA'] = sub_subset_data[outcome].rolling(window=12).mean()\n",
    "        ax.plot(sub_subset_data['month'], sub_subset_data[outcome], label=journal,\n",
    "                alpha=0.7, color=colors[journal], linestyle='-')\n",
    "\n",
    "    ax.plot(subset_data['month'], subset_data['y_norm'], color='black', alpha=0.8, linestyle='dotted')\n",
    "    ax.set_title(f\"{alignment}\")\n",
    "    ax.legend()\n",
    "\n",
    "add_shaded_periods(axes, main_elec_months, color='black', alpha=0.1)\n",
    "\n",
    "plt.suptitle(\"\"\"\n",
    "Mentions Distribution by Political Affiliation and Journal\\n\n",
    "Observed vs. Predicted Values\n",
    "\"\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/journals_mentions_val_graph.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccb0ee-726d-4ff5-8f9a-ec6e7d7f1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff1 = pd.Period('2002-06', freq='M')\n",
    "cutoff2 = pd.Period('2017-06', freq='M')\n",
    "\n",
    "results = []\n",
    "\n",
    "for period_label, period_filter in {\n",
    "    '1981-2002': model_data[\"month\"] < cutoff1,\n",
    "    '2002-2017': (model_data[\"month\"] >= cutoff1) & (model_data[\"month\"] < cutoff2),\n",
    "    '2017-2024': model_data[\"month\"] >= cutoff2\n",
    "}.items():\n",
    "    period_data = model_data[period_filter]\n",
    "    \n",
    "    for alignment in period_data[\"political_alignment\"].unique():\n",
    "        subset_data = period_data[period_data[\"political_alignment\"] == alignment]\n",
    "        \n",
    "        for journal in subset_data[\"journal\"].unique():\n",
    "            sub_subset_data = subset_data[subset_data[\"journal\"] == journal]\n",
    "            y = sub_subset_data[outcome]\n",
    "            y_norm = sub_subset_data['y_norm']\n",
    "            metrics = compute_proportional_metrics(y_norm, y)\n",
    "            results.append({\n",
    "                'period': period_label,\n",
    "                'alignment': alignment,\n",
    "                'journal': journal,\n",
    "                '% correct prescriptions': 100 * metrics['TP'],\n",
    "                '% excess prescriptions': 100 * metrics['FP'],\n",
    "                '% missing prescriptions': 100 * metrics['FN']})\n",
    "\n",
    "summary = pd.DataFrame(results)\n",
    "summary[\"alignment\"] = pd.Categorical(summary[\"alignment\"], categories=nuances_order, ordered=True)\n",
    "summary = summary.pivot_table(index=([\"alignment\", \"journal\"]),\n",
    "                                    columns=\"period\",\n",
    "                                    values=[\"% correct prescriptions\",\n",
    "                                            \"% excess prescriptions\",\n",
    "                                            \"% missing prescriptions\"],\n",
    "                                    observed=False)\n",
    "summary = summary.reset_index()\n",
    "summary.style.hide(axis=\"index\").format({col: \"{:.3f}\" for col in summary.columns[2:]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
