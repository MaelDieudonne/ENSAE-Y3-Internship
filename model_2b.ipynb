{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f01ac-0bed-4316-a938-35e7f77a7c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import root_mean_squared_error as root_mse\n",
    "\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb8e26a-8690-46a2-8dc4-4fc5bf59f509",
   "metadata": {},
   "source": [
    "# Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4198e5a-26bc-4d27-8fee-7ababcb34b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ee3ce-535a-4db2-af52-ffac183b40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_no_journal = pd.read_parquet(\"data/model_data_no_journal.parquet\")\n",
    "model_data = pd.read_parquet(\"data/model_data.parquet\")\n",
    "\n",
    "# model_data_no_journal = model_data_no_journal[model_data_no_journal['political_alignment'] != 'autre']\n",
    "# model_data = model_data[model_data['political_alignment'] != 'autre']\n",
    "\n",
    "nuances_order = [\"Far right\", \"Right\", \"Center\", \"Left\", \"Far left\", \"Other\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b02da-ba4d-41e4-8162-2cecb4744597",
   "metadata": {},
   "source": [
    "Indicatrices temporelles :\n",
    "- `pres_dummy` = 3 mois précédant une élection présidentielle\n",
    "- `europ_dummy_short` = 3 mois suivant une élection européenne\n",
    "- `europ_dummy_long` = d'une élection européenne à l'élection présidentielle suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17fca8-1a73-4fa3-b2f3-79cccc17c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data['next_pres_votes_share'] = model_data['pres_dummy'] * model_data['pres_votes_share']\n",
    "model_data['europ_votes_short'] = (model_data['europ_votes_share'] * model_data['europ_dummy_short'])\n",
    "model_data['europ_votes_long'] = (model_data['europ_votes_share'] * model_data['europ_dummy_long'])\n",
    "\n",
    "model_data_no_journal['next_pres_votes_share'] = model_data_no_journal['pres_dummy'] * model_data_no_journal['pres_votes_share']\n",
    "model_data_no_journal['europ_votes_short'] = (model_data_no_journal['europ_votes_share'] * model_data_no_journal['europ_dummy_short'])\n",
    "model_data_no_journal['europ_votes_long'] = (model_data_no_journal['europ_votes_share'] * model_data_no_journal['europ_dummy_long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a140f-5111-434d-ab77-95e8de9163f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "presi_dates = [\n",
    "    \"26/04/1981\", \"10/05/1981\",\n",
    "    \"24/04/1988\", \"08/05/1988\",\n",
    "    \"23/04/1995\", \"07/05/1995\",\n",
    "    \"21/04/2002\", \"05/05/2002\",\n",
    "    \"22/04/2007\", \"06/05/2007\",\n",
    "    \"22/04/2012\", \"06/05/2012\",\n",
    "    \"21/04/2017\", \"07/05/2017\",\n",
    "    \"10/04/2022\", \"24/04/2022\"]\n",
    "presi_months = pd.to_datetime(presi_dates, dayfirst=True).to_period('M').drop_duplicates()\n",
    "\n",
    "legi_dates = [\n",
    "    \"14/06/1981\", \"21/06/1981\",\n",
    "    \"16/03/1986\",\n",
    "    \"05/06/1988\", \"11/06/1988\",\n",
    "    \"21/03/1993\", \"28/03/1993\",\n",
    "    \"25/05/1997\", \"01/06/1997\",\n",
    "    \"09/06/2002\", \"16/06/2002\",\n",
    "    \"10/06/2007\", \"17/06/2007\",\n",
    "    \"10/06/2012\", \"17/06/2012\",\n",
    "    \"11/06/2017\", \"18/06/2017\",\n",
    "    \"12/06/2022\", \"19/06/2022\",\n",
    "    \"29/06/2024\", \"06/07/2024\"]\n",
    "legi_months = pd.to_datetime(legi_dates, dayfirst=True).to_period('M').drop_duplicates()\n",
    "\n",
    "regio_dates = [\n",
    "    \"16/03/1986\",\n",
    "    \"22/03/1992\",\n",
    "    \"15/03/1998\",\n",
    "    \"21/03/2004\", \"28/03/2004\",\n",
    "    \"14/03/2010\", \"21/03/2010\",\n",
    "    \"06/12/2015\", \"13/12/2015\",\n",
    "    \"20/06/2021\", \"27/06/2021\"]\n",
    "regio_months = pd.to_datetime(regio_dates, dayfirst=True).to_period('M').drop_duplicates()\n",
    "\n",
    "canto_dates = [\n",
    "    \"14/03/1982\", \"21/03/1982\",\n",
    "    \"10/03/1985\", \"17/03/1985\",\n",
    "    \"25/09/1988\", \"02/10/1988\",\n",
    "    \"20/03/1992\", \"27/03/1992\",\n",
    "    \"15/03/1998\", \"22/03/1998\",\n",
    "    \"11/03/2001\", \"18/03/2001\",\n",
    "    \"21/03/2004\", \"28/03/2004\",\n",
    "    \"9/03/2008\", \"16/03/2008\",\n",
    "    \"20/03/2011\", \"27/03/2011\"]\n",
    "canto_months = pd.to_datetime(canto_dates, dayfirst=True).to_period('M').drop_duplicates()\n",
    "\n",
    "dept_dates = [\n",
    "    \"22/03/2015\", \"29/03/2015\",\n",
    "    \"20/06/2021\", \"27/06/2021\"]\n",
    "dept_months = pd.to_datetime(dept_dates, dayfirst=True).to_period('M').drop_duplicates()\n",
    "\n",
    "muni_dates = [\n",
    "    \"06/03/1983\", \"13/03/1983\",\n",
    "    \"12/03/1989\", \"19/03/1989\",\n",
    "    \"11/06/1995\", \"18/06/1995\",\n",
    "    \"11/03/2001\", \"18/03/2001\",\n",
    "    \"09/03/2008\", \"16/03/2008\",\n",
    "    \"23/03/2014\", \"30/03/2014\",\n",
    "    \"15/03/2020\", \"28/06/2020\"]\n",
    "muni_months = pd.to_datetime(muni_dates, dayfirst=True).to_period('M').drop_duplicates()\n",
    "\n",
    "europ_dates = [\n",
    "    \"17/06/1984\",\n",
    "    \"18/06/1989\",\n",
    "    \"12/06/1994\",\n",
    "    \"13/06/1999\",\n",
    "    \"13/06/2004\",\n",
    "    \"07/06/2009\",\n",
    "    \"25/05/2014\",\n",
    "    \"26/05/2019\",\n",
    "    \"09/06/2024\"]\n",
    "europ_months = pd.to_datetime(europ_dates, dayfirst=True).to_period('M').drop_duplicates()\n",
    "\n",
    "main_elec_dates = presi_dates + legi_dates + europ_dates\n",
    "main_elec_months = pd.to_datetime(main_elec_dates, dayfirst=True).to_period('M').drop_duplicates().sort_values()\n",
    "\n",
    "other_elec_dates = regio_dates + canto_dates + dept_dates + muni_dates\n",
    "other_elec_months = pd.to_datetime(other_elec_dates, dayfirst=True).to_period('M').drop_duplicates().sort_values()\n",
    "\n",
    "def add_shaded_periods(ax_list, periods, color, alpha):\n",
    "    start_period = None\n",
    "    for i, period in enumerate(periods):\n",
    "        if start_period is None:\n",
    "            start_period = period\n",
    "        is_last = (i == len(periods) - 1)\n",
    "        is_gap = (not is_last and periods[i + 1] != period + 1)\n",
    "        if is_last or is_gap:\n",
    "            end_period = period\n",
    "            start = start_period.to_timestamp()\n",
    "            end = (end_period + MonthEnd(1)).to_timestamp()\n",
    "            for ax in ax_list:\n",
    "                ax.axvspan(start, end, color=color, alpha=alpha)\n",
    "            start_period = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a39eccbe-f34a-4879-a8f1-1c43361f640b",
   "metadata": {},
   "source": [
    "# Méthode\n",
    "Nous cherchons à expliquer le volume des citations attribuées aux différentes nuances politiques, qui reflète le degré auquel la parole leur est donnée. Sa modélisation économétrique est délicate pour trois raisons.\n",
    "1. **Les pratiques journalistiques sont fortement normées.** Elles sont soumises à un principe de neutralité, se traduisant par une norme de représentativité : la couverture des partis politiques, et des personnalités qui les représentent, doit refléter leur importance dans la vie politique. Le volume des citations ne peut donc s'interpréter qu'en relation à cette norme. Dans quelle mesure est-elle suivie ? L'est-elle à l'identique par toutes les rédactions, pour toutes les nuances politiques, à toutes les périodes ?\n",
    "2.\t**Le volume des citations subit des tendances importantes sur la période étudiée**, en raison principalement du basculement de l'imprimé vers Internet. Or, ces tendances sont décorrélées des potentiels régresseurs, car leur importance dans la vie politique ne peut croître ou se réduire simultanément pour toutes les nuances politiques. Cela rend difficile l'élimination des tendances, les effets fixes capturant l'essentiel des relations au détriment des régresseurs. Le seul remède est de normaliser le volume des citations en se ramenant aux proportions des citations attribuées à chaque nuance politique. Mais l'on se heurte alors de manière particulièrement visible à la difficulté suivante.\n",
    "3.\t**Les données présentent une double compositionnalité**, c'est-à-dire qu'elles sont des fractions de sommes stables.\n",
    "  - C'est bien le cas des proportions de citations, dont la somme est par construction égale à un, mais aussi du volume des citations, dans la mesure où leur nombre total est contraint à court terme : les journaux ne peuvent citer un nombre infini de personnalités à chaque période, car le nombre d'articles qu'ils publient est limité par des enjeux de production et de diffusion. Ils doivent donc décider comment ils répartissent articles et citations entre les nuances politiques, ce qui engendre des dépendances complexes : toute citation attribuée à une nuance politique est aussi non-attribuée aux autres.\n",
    "  - Il en va de même pour les régresseurs. Considérons par exemple les résultats électoraux : le nombre total d'électeurs étant fixé à chaque élection, toute voix obtenue par un parti est aussi une voix dont sont privés les autres.\n",
    "  - Or, il existe des instruments statistiques permettant de traiter la compositionnalité des outcomes, notamment les régressions Dirichlet, mais il est extrêmement compliqué d'y intégrer la compositionnalité des régresseurs, alors que leur interprétation peut s'avérer très délicate. Les instruments statistiques traditionnels, pour leur part, risquent d'aboutir à des résultats incohérents : typiquement, une somme des proportions des citations attribuées à chaque nuance politique supérieure à un, signifiant que l'effet des régresseurs est surestimé.\n",
    "\n",
    "Nous proposons une solution ne cherchant pas à modéliser le plus précisément possible des phénomènes réels, mais à étudier leur écart à des phénomènes de référence. Cette approche prend sens relativement au caractère normé des activités journalistiques. Elle consiste à estimer les proportions des citations attribuées à chaque nuance politique qu'on devrait observer si les journalistiques respectaient parfaitement la norme de représentativité, c'est-à-dire les proportions ***normales***, pour mesurer à quel point les proportions effectives s'en écartent.\n",
    "\n",
    "Dans cette perspective, la légitimation / normalisation de l'ED pourrait prendre deux formes.\n",
    "1.\tUne déconnexion croissante entre sa couverture médiatique et son importance dans la vie politique, en partant d'une situation où la norme de représentativité était respectée, les journalistes citent davantage les personnalités d'ED qu'ils ne le devraient, et ne le faisaient initialement.\n",
    "2.\tUne connexion croissante, en partant d'une situation où la norme n'était pas respectée, car l'ED était diabolisée : les journalistes citent autant les personnalités d'ED qu'ils le doivent, alors qu'ils les citaient moins initialement.\n",
    "\n",
    "Cette approche permet de respecter les contraintes découlant de la compositionnalité des données tout en fournissant des résultats interprétables, car demeurant dans le cadre d'un modèle linéaire. En effet, la norme de représentativité devrait engendrer une proportionnalité entre l'importance des partis dans la vie politique et leur couverture, autrement dit, une relation linéaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cc2a99-e18f-4864-9c74-3dd4770c55c4",
   "metadata": {},
   "source": [
    "## Spécification de la norme\n",
    "Formalisons maintenant cette norme. Indiçons par $i$ les nuances politiques ($n$ au total) et $t$ les périodes, puis notons $Y_{it}$ la proportion des citations reçues par la nuance $i$ à la période $t$ et $Y_{it}^{norm}$ qu'elle devrait normalement recevoir. \n",
    "Supposons également qu'à chaque période :\n",
    "- Chaque nuance reçoit une fraction incompressible des citations, c'est-à-dire qu'elle bénéficie d'une couverture médiatique minimale même lorsque son poids électoral et institutionnel est nul. Cette fraction est notée $\\alpha$. L'hypothèse $\\alpha>0$ est plausible dans la mesure où les nuances politiques rassemblent plusieurs partis, et où l'un au moins de ces partis est toujours suffisamment important pour recevoir l'attention des journalistes. Elle est vérifiée ci-dessosu dans les données, y compris à l'échelle des journaux.\n",
    "- La nuance politique au gouvernement reçoit une fraction fixe des citations, notée $\\theta$, reflétant la couverture médiatique de l'action gouvernementale (en notant $G_{it}$ l'indicatrice valant 1 si le Premier ministre appartient à la nuance politique $i$ durant la période $t$).\n",
    "- Les citations restantes sont réparties entre les nuances politiques en fonction de leur poids dans la vie politique, estimé par la moyenne pondérée de la proportion des sièges qu'elles détiennent à l'Assemblée nationale (notée ${AN}_{it}$ et pondérée par $\\beta$) et du score qu'elles ont obtenu au premier tour de la dernière élection présidentielle (notée $P_{it}$ et pondérée par $\\gamma$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acdc5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = \"quotes_share\"\n",
    "print(f\"Number of null outcomes: {(model_data[outcome] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29138a4-ae77-4ed7-aad0-69d7263f5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misleading, null outcomes are excluded when building the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049ba26-f21b-4186-9ddf-24dd59b2907a",
   "metadata": {},
   "source": [
    "La norme de représentativité se manifeste alors par la relation suivante : \n",
    "$$Y_{it}^{norm} = \\alpha + \\beta AN_{it} + \\gamma P_{it} + \\theta G_{it}$$\n",
    " \n",
    "L'identité des coefficients sont identiques pour l'ensemble des nuances politiques et des périodes signifie que la norme s'applique de la même façon à l'ensemble du spectre politique, et n'évolue pas au cours du temps (par exemple avec un poids croissant accordé à l'action gouvernementale). \n",
    " \n",
    "Par ailleurs, dans la mesure où les élections présidentielles et législatives se suivent généralement de près, ce modèle normatif prévoit des proportions de citations constantes au cours des cycles électoraux. Il ne s'agit évidemment pas d'un phénomène que nous imaginons observer, en particulier car la couverture médiatique de la vie politique reflète de nombreuses dynamiques transitoires. Mais à moyen terme ou à l'échelle des cycles électoraux, les proportions des citations devraient graviter autour de leurs valeurs normales.\n",
    "\n",
    "Les contraintes de compositionnalité sont les suivantes ($\\forall t$) :\n",
    "- $\\sum_{i=1}^{n} Y_{it} = 1$\n",
    "- $\\sum_{i=1}^{n} {AN}_{it} = 1$\n",
    "- $\\sum_{i=1}^{n} P_{it} = 1$\n",
    "- $\\sum_{i=1}^{n} G_{it} = 1$\n",
    " \n",
    "Les contraintes d'interprétations, impliquant notamment des coefficients positifs, sont les suivantes :\n",
    "- $0< \\alpha <1$ \n",
    "- $0< \\theta <1$ \n",
    "- $0< \\beta, \\gamma <1$ et $\\beta + \\gamma = 1$ \n",
    " \n",
    "Et l'on doit bien sûr avoir $\\forall (i,t) : 0 < Y_{it}^{norm} < 1$ \n",
    " \n",
    "Ces conditions sont vérifiées en spécifiant le modèle ainsi : \n",
    "$$Y_{it}^{norm} = \\alpha + (1 - n*alpha - \\theta)(\\beta {AN}_{it} + \\gamma P_{it}) + \\theta G_{it}$$\n",
    "\n",
    "Comment déterminer la valeur de ces coefficients ?\n",
    "\n",
    "Une première possibilité est de les estimer à partir des valeurs observées, en minimisant une fonction de perte (typiquement l'erreur quadratique) sous les contraintes précédentes. Cette approche est problématique pour au moins trois raisons.\n",
    "1.\tLes données ne sont pas homogènes : elles ne sont pas disponibles pour tous les journaux à toutes les périodes, signifiant que certains vont peser davantage dans l'estimation. Cela risque d'engendrer des biais implicites, car l'estimation reflètera davantage les pratiques de certaines rédactions que les comportements moyens des journalistes.\n",
    "2.\tSi la norme de représentativité est peu respectée, les résultats conduiront à sous-estimer les déviations qui s'opèrent en pratique.\n",
    "3.\tUne solution à ces deux difficultés serait de pouvoir identifier des situations dans lesquelles le respect de la norme est assurée, notamment en sélectionnant un journal et/ou une période de référence. Mais cela revient à prendre parti dans le champ médiatique, ce qui est contestable. Par ailleurs, quelles que soient les données utilisées pour l'estimation, l'existence d'une solution optimale n'est pas acquise : rien n'assure que le modèle dispose d'une solution unique et converge vers elle.\n",
    "\n",
    "Une possibilité alternative consiste à spécifier les coefficients *a priori* à partir de sources externes sur les pratiques des rédactions, en posant par exemple :\n",
    "- $\\alpha = 0,01 \\Rightarrow$ toute nuance politique reçoit au moins 1 % des citations.\n",
    "- $\\beta = 0,666$ et $\\gamma = 0,333 \\Rightarrow$ pour appréhender l'importance des nuances dans la vie politique, les journalistes accordent un poids de 2/3 à la proportion de députés qu'elles détiennent et 1/3 à leur score aux présidentielles.\n",
    "- $\\theta = 0,2 \\Rightarrow$ la nuance politique au pouvoir reçoit 20 % des citations à ce titre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ecb2c-a5d4-4653-8bb9-f677e088159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "beta = 0.666\n",
    "gamma = 0.333\n",
    "theta = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad23ddd3-ba42-4072-93f4-f956332c8298",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(model_data_no_journal['political_alignment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6191727a-139d-4209-87cc-3e42240a21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_month = pd.Period('2005-2', freq='M')\n",
    "ex_data = model_data_no_journal[model_data_no_journal[\"month\"] == ex_month][[\"political_alignment\", \"na_share\", \"pres_votes_share\", \"government\", outcome]]\n",
    "ex_data['y_norm'] = (\n",
    "    alpha +\n",
    "    beta * (1 - n*alpha - theta) * ex_data[\"na_share\"] + \n",
    "    gamma * (1 - n*alpha - theta) * ex_data[\"pres_votes_share\"] +\n",
    "    theta * ex_data[\"government\"])\n",
    "ex_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b7a2c-f29b-4a67-b5ae-92ef651e7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_month = pd.Period('2005-3', freq='M')\n",
    "ex_data = model_data_no_journal[model_data_no_journal[\"month\"] == ex_month][[\"political_alignment\", \"na_share\", \"pres_votes_share\", \"government\", outcome]]\n",
    "ex_data['y_norm'] = (\n",
    "    alpha +\n",
    "    beta * (1 - n*alpha - theta) * ex_data[\"na_share\"] + \n",
    "    gamma * (1 - n*alpha - theta) * ex_data[\"pres_votes_share\"] +\n",
    "    theta * ex_data[\"government\"])\n",
    "ex_data = ex_data.rename(columns={\n",
    "    \"quotes_share\": \"observed_quotes_share\",\n",
    "    \"y_norm\": \"normal_quotes_share\"})\n",
    "ex_data[\"political_alignment\"] = pd.Categorical(\n",
    "    ex_data[\"political_alignment\"],\n",
    "    categories=nuances_order,\n",
    "    ordered=True)\n",
    "ex_data = ex_data.sort_values(\"political_alignment\")\n",
    "\n",
    "print(\"Regressors:\")\n",
    "print(f\"- Sum of seats at National Assembly: {ex_data['na_share'].sum():.3f}\")\n",
    "print(f\"- Sum of votes at the last presidential election: {ex_data['pres_votes_share'].sum():.3f}\")\n",
    "print(\"\")\n",
    "print(f\"Observed and normal quotes share for {ex_month}:\")\n",
    "print(f\"- Sum of observed values: {ex_data['observed_quotes_share'].sum()}\")\n",
    "print(f\"- Sum of normal values: {ex_data['normal_quotes_share'].sum():.3f}\")\n",
    "print(\"\")\n",
    "ex_data.style.hide(axis=0).format(\n",
    "    {col: \"{:.3f}\" for col in ex_data.columns if col != \"political_alignment\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19286d8c-266a-4051-9a42-6c091cfd53aa",
   "metadata": {},
   "source": [
    "## Mesure de la distance entre les valeurs normales et observées\n",
    "Dans une approche économétrique classique, l'interprétation du modèle s'appuierait principalement sur les coefficients estimés et leur significativité. Cela n'aurait pas de sens ici, puisque les coefficients sont prédéfinis. On utilise donc d'autres grandeurs pour caractériser l'écart entre les prescriptions du modèle et les valeurs observées, c'est-à-dire entre les comportements normaux et réels.\n",
    "- Les **résidus moyens** $\\text{(mean residuals / MR)} = \\frac{1}{n} \\sum_{t=t_0}^{t_1} Y_{it} - Y_{it}^{norm}$\n",
    "  - Ils sont positifs lorsqu'une nuance politique reçoit davantage de citations (en proportion) qu'elle ne le devrait d'après la norme de représentativité au cours d'un intervalle de temps donné.\n",
    "  - <span style=\"background-color: yellow\">*Exemple de lecture*</span>\n",
    "  - Les écarts de signes se compensent. \n",
    "\n",
    "Ceci permet d'éliminer les fluctuations à court terme. \n",
    "En effet, on ne s'attend pas à ce que la norme de représentativité soit respectée *à chaque période* en raison du caractère imprévisible ou cyclique de l'actualité. \n",
    "\n",
    "L'important est qu'elle soit respectée tendenciellement, aléas de la couverture à court terme, dont les rédactions ontl iberté pour s'emparer.\n",
    "\n",
    "(Malgré un modèle qui serait considéré comme peu prédictif avec une approche économétrique classique).\n",
    "\n",
    "*NB: avec les OLS, les résidus moyens seraient nuls par construction. Rien ne permet ici d'assurer que ce sera la cas. De surcroît ce sont les résidus moyens par nuance politique (ainsi qu'éventuellement journal / période) qui nous intéressent.*\n",
    "\n",
    "  - <span style=\"background-color: yellow\">*Calculer aussi leur variance*</span>\n",
    "- Les **résidus moyens relatifs** $\\text{(mean relative residuals / MRR)} = \\frac{1}{n} \\sum_{t=t_0}^{t_1} \\frac{Y_{it} - Y_{it}^{norm}}{Y_{it}^{norm}}$\n",
    "  - Normalisation par rapport aux valeurs normales (plutôt qu'aux valeurs observées comme dans les approches économétriques classiques) car celles-ci priment dans l'interprétation\n",
    "  - Permet de compenser les écarts entre les valeurs moyennes selon les nuances politiques.\n",
    "  - Mais risque d'engendrer des valeurs très élevées quand les valeurs normales sont faibles, plus délicat à interpréter.\n",
    "  - Borne inférieure à - 100\n",
    "  - Prendre $\\frac{Y_{it} - Y_{it}^{norm}$ plutôt ?\n",
    "  - <span style=\"background-color: yellow\">*Exemple de lecture*</span>\n",
    "\n",
    "\n",
    "\n",
    "Autres grandeurs qui servent davantage à mesurer la qualité prédictive, en revenant à une approche plus classique, qui considèrent les déviations en valeur absolue, sans compensation lorsqu'elles sont de signe opposé :\n",
    "- $\\text{Mean absolute percentage error (MAPE)} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{\\hat{y}_i - y_i}{\\hat{y}_i} \\right| \\Rightarrow$ Ils correspondent à la moyenne des résidus relatifs en valeur absolue, et s'interprètent directement : une MAPE de 1 signifie que les valeurs réelles s'écartent en moyenne de 100 % des valeurs prescrites, dans un sens ou dans l'autre.\n",
    "- $\\text{Root mean squared percentage error (RMSPE)} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} \\Rightarrow$ Elle ne s'interprète pas directement mais permet aussi de comparer les modèles, en étant plus sensible aux outliers que la MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd79bcb-7d91-44f1-8e5c-a7ad900f5927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_r(y_true, y_pred):\n",
    "    return ((y_true - y_pred)).mean()\n",
    "\n",
    "# def mean_rr(y_true, y_pred):\n",
    "#    return (y_true / y_pred).mean()\n",
    "\n",
    "def mean_rr(y_true, y_pred):\n",
    "   return ((y_true - y_pred) / y_pred).mean()\n",
    "\n",
    "def mean_ape(y_true, y_pred):\n",
    "    return ((np.abs(y_true - y_pred) / y_pred).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e4b32-677e-4720-974e-b749f694fb09",
   "metadata": {},
   "source": [
    "## ...\n",
    "La démarche actuelle consiste à comparer ces indicateurs selon les variables d'intérêt : nuances politiques, journaux, périodes et leurs interactions.\n",
    " \n",
    "Une démarche plus formelle serait de régresser les résidus du modèle normatif sur les variables d'intérêt. \n",
    "- Elle doit revenir au même que la précédente en l'absence de constante dans les régressions, dont les coefficients correspondent alors aux moyennes des résidus observées sur les sous-populations définies par les modalités des variables d'intérêt.\n",
    "- Mais elle permet probablement d'aller plus loin…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc3a4b-d335-47d9-94dd-ecabfd9826fb",
   "metadata": {},
   "source": [
    "# Modèle normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea05fd8-e4ff-40b4-ad3b-4b25f01e7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_norm = (\n",
    "    alpha +\n",
    "    beta * (1 - n*alpha - theta) * model_data_no_journal[\"na_share\"] + \n",
    "    gamma * (1 - n*alpha - theta) * model_data_no_journal[\"pres_votes_share\"] +\n",
    "    theta * model_data_no_journal[\"government\"])\n",
    "\n",
    "y = model_data_no_journal[outcome]\n",
    "\n",
    "r2 = r2_score(y, y_norm)\n",
    "mr = mean_r(y, y_norm)\n",
    "mrr = mean_rr(y, y_norm)\n",
    "mape = mean_ape(y, y_norm)\n",
    "rmspe = root_mse(y, y_norm)\n",
    "\n",
    "print(f\"R2: {100*r2:.2f}%\")\n",
    "print(f\"MR: {100*mr:.2f}%\")\n",
    "print(f\"MRR: {100*mrr:.2f}%\")\n",
    "print(f\"MAPE: {100*mape:.2f}%\")\n",
    "print(f\"RMSPE: {rmspe:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af962b4a",
   "metadata": {},
   "source": [
    "<span style=\"background-color: yellow\">*Commentaire*</span>\n",
    "\n",
    "Les résidus moyens ne sont pas nuls donc le modèle n'est pas centré comme avec une régression ordinaire, il reste un biais systématique des prévisions, légèrement inférieures en moyenne aux valeurs réelles (de 2 points de pourcentage)\n",
    "\n",
    "Résidus relatifs moyens négatifs = le biais n'est pas identique selon la distribution des valeurs normales. Il est négatif lorsque les valeurs normales sont importantes, mais positifs lorsque les valeurs normales sont faibles. Or la normalisation fait que les valeurs normales faibles pèsent davantage sur la moyenne des résidus relatifs.\n",
    "\n",
    "C'est exactement ce qu'on observe dans les graphs ci-après : le modèle surprescrit pour les extrêmes, et sous-prescrit pour les partis mainstream.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e209b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_diff = y - y_norm\n",
    "rel_diff = (y - y_norm) / y_norm\n",
    "\n",
    "print(f\"Moyenne des valeurs normales : {y_norm.mean():.5f}\")\n",
    "print(f\"Moyenne des valeurs réelles : {y.mean():.5f}\")\n",
    "print(\"\")\n",
    "print(f\"Moyenne des résidus positifs (sous-estimation) : {abs_diff[abs_diff > 0].mean():.5f}\")\n",
    "print(f\"Moyenne des résidus négatifs (sur-estimation) : {abs_diff[abs_diff < 0].mean():.5f}\")\n",
    "print(\"\")\n",
    "print(f\"Moyenne des résidus relatifs positifs (sous-estimation) : {rel_diff[rel_diff > 0].mean():.5f}\")\n",
    "print(f\"Moyenne des résidus relatifs négatifs (sur-estimation) : {rel_diff[rel_diff < 0].mean():.5f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.hist(abs_diff, bins=50, color='skyblue', edgecolor='black', density=True)\n",
    "plt.title('Distribution of Absolute Residuals')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Relative Frequency')\n",
    "plt.grid(True, linestyle='--', alpha=0.35)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b51771",
   "metadata": {},
   "source": [
    "## Comparaison avec les OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32184345",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(f\"{outcome} ~ na_share + pres_votes_share + government\", \n",
    "                data=model_data_no_journal).fit(cov_type='HC3')\n",
    "y = model_data_no_journal[outcome]\n",
    "y_pred = model.predict(model_data_no_journal)\n",
    "\n",
    "r2 = r2_score(y, y_pred)\n",
    "mr = mean_r(y, y_pred)\n",
    "mrr = mean_rr(y, y_pred)\n",
    "mape = mean_ape(y, y_pred)\n",
    "rmspe = root_mse(y, y_pred)\n",
    "\n",
    "print(f\"R2: {100*r2:.2f}%\")\n",
    "print(f\"MR: {100*mr:.2f}%\")\n",
    "print(f\"MRR: {100*mrr:.2f}%\")\n",
    "print(f\"MAPE: {100*mape:.2f}%\")\n",
    "print(f\"RMSPE: {rmspe:.5f}\")\n",
    "\n",
    "params = model.params.rename(\"coef\").to_frame()\n",
    "pvalues = model.pvalues.rename(\"pval\").to_frame()\n",
    "results = pd.merge(params, pvalues, left_index=True, right_index=True)\n",
    "results = results[results['pval'] <= 0.1]\n",
    "results.style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2712d",
   "metadata": {},
   "source": [
    "On voit que le modèle est désormais centré, avec des résidus moyens nuls. Il est nécessaire d'introduire une constante négative pour cela, qui ne fait pas vraiment sens : cela signifierait que la proportion de citations que reçoivent par défaut les nuances politiques est négative.\n",
    "\n",
    "*NB: cela pourrait témoigner de relations non-linéaires, mais c'est une possibilité que nous n'avons pas envie d'explorer, car la norme de representativité conduit à supposer des relations proportionnelles.*\n",
    "\n",
    "Par ailleurs, les résultats du modèle OLS sont incohérents.\n",
    "D'une part, il prédit un nombre substantiel de proportions négatives.\n",
    "D'autre part, il ne prédit aucun ensemble cohérent de proportions, sommant à 1 pour la période concernée, avec des écarts substantiels autour de cette valeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58044ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_no_journal['y_pred'] = y_pred\n",
    "\n",
    "print(f\"Number of <0 predictions: {(model_data_no_journal['y_pred'] < 0).sum()}\")\n",
    "print(f\"Number of >1 predictions: {(model_data_no_journal['y_pred'] > 1).sum()}\")\n",
    "print(\"\")\n",
    "print(f\"Number of periods where predictions sums <1 : {(model_data_no_journal.groupby('month')['y_pred'].sum() < 1).sum()}\")\n",
    "print(f\"Number of periods where predictions sums =1 : {(model_data_no_journal.groupby('month')['y_pred'].sum() == 1).sum()}\")\n",
    "print(f\"Number of periods where predictions sums >1 : {(model_data_no_journal.groupby('month')['y_pred'].sum() > 1).sum()}\")\n",
    "print(\"\")\n",
    "\n",
    "monthly_pred_sum = model_data_no_journal.groupby('month')['y_pred'].sum()\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.hist(monthly_pred_sum, bins=50, color='skyblue', edgecolor='black', density=True)\n",
    "plt.axvline(x=1, color='darkorange', linewidth=1, linestyle='--', label='x = 1')\n",
    "plt.title('Distribution of the Sums of Monthly Predictions from the OLS Model')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Relative Frequency')\n",
    "plt.grid(True, linestyle='--', alpha=0.35)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc1d0c-63f9-41f5-b759-4bdba2ed3a3e",
   "metadata": {},
   "source": [
    "## Détermination des valeurs optimales respectant les contraintes de compositionnalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2633483-1ec9-46dc-8caa-3282e87022e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizing RMSPE (as in OLS models) (the program does not converge with other loss functions)\n",
    "data_opt = model_data_no_journal[[\"na_share\", \"pres_votes_share\", \"government\"]]\n",
    "y_opt = model_data_no_journal[outcome]\n",
    "\n",
    "def objective(params):\n",
    "    alpha, beta, theta = params[0], params[1], params[2]\n",
    "    gamma = 1 - beta\n",
    "    y_pred = (\n",
    "        alpha +\n",
    "        beta * (1 - n * alpha - theta) * data_opt[\"na_share\"] +\n",
    "        gamma * (1 - n * alpha - theta) * data_opt[\"pres_votes_share\"] +\n",
    "        theta * data_opt[\"government\"]\n",
    "    )\n",
    "    return root_mse(y_opt, y_pred)\n",
    "\n",
    "initial_guess = [0.01, 0.666, 0.1]\n",
    "\n",
    "result = minimize(\n",
    "    objective,\n",
    "    initial_guess,\n",
    "    bounds=[(0, 1), (0, 1), (0, 1)],\n",
    "    method='SLSQP')\n",
    "\n",
    "if result.success:\n",
    "    alpha_opt, beta_opt, theta_opt = result.x\n",
    "    gamma_opt = 1 - beta_opt\n",
    "    print(f\"Optimal alpha: {alpha_opt:.5f}\")\n",
    "    print(f\"Optimal beta: {beta_opt:.5f}\")\n",
    "    print(f\"Optimal gamma: {gamma_opt:.5f}\")\n",
    "    print(f\"Optimal theta: {theta_opt:.5f}\")\n",
    "else:\n",
    "    print(\"Optimization failed:\", result.message)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "y_norm_opt = (\n",
    "    alpha_opt +\n",
    "    beta_opt * (1 - n*alpha_opt - theta_opt) * model_data_no_journal[\"na_share\"] + \n",
    "    gamma_opt * (1 - n*alpha_opt - theta_opt) * model_data_no_journal[\"pres_votes_share\"] +\n",
    "    theta_opt * model_data_no_journal[\"government\"])\n",
    "\n",
    "r2 = r2_score(y, y_norm_opt)\n",
    "mr = mean_r(y, y_norm_opt)\n",
    "mrr = mean_rr(y, y_norm_opt)\n",
    "mape = mean_ape(y, y_norm_opt)\n",
    "rmspe = root_mse(y, y_norm_opt)\n",
    "\n",
    "print(f\"R2: {100*r2:.2f}%\")\n",
    "print(f\"MR: {100*mr:.2f}%\")\n",
    "print(f\"MRR: {100*mrr:.2f}%\")\n",
    "print(f\"MAPE: {100*mape:.2f}%\")\n",
    "print(f\"RMSPE: {rmspe:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d51896",
   "metadata": {},
   "source": [
    "Premier constat : la constante est éliminée, de sorte que certaines valeurs normales deviennent nulles, et que les résidus relatifs ne sont plus calculables.\n",
    "\n",
    "Les autres valeurs ne sont pas si différentes des nôtres, et les performances du modèle à peine meilleures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad61e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = pd.Period('2012-06', freq='M')\n",
    "\n",
    "data_opt = model_data[(model_data[\"month\"] < cutoff) & \n",
    "                                (model_data[\"journal\"] == \"Le Monde\")][[\"na_share\", \"pres_votes_share\", \"government\"]]\n",
    "y_opt = model_data[(model_data[\"month\"] < cutoff) & \n",
    "                                (model_data[\"journal\"] == \"Le Monde\")][outcome]\n",
    "\n",
    "def objective(params):\n",
    "    alpha, beta, theta = params[0], params[1], params[2]\n",
    "    gamma = 1 - beta\n",
    "    y_pred = (\n",
    "        alpha +\n",
    "        beta * (1 - n * alpha - theta) * data_opt[\"na_share\"] +\n",
    "        gamma * (1 - n * alpha - theta) * data_opt[\"pres_votes_share\"] +\n",
    "        theta * data_opt[\"government\"]\n",
    "    )\n",
    "    return root_mse(y_opt, y_pred)\n",
    "\n",
    "initial_guess = [0.01, 0.5, 0.1]\n",
    "\n",
    "result = minimize(\n",
    "    objective,\n",
    "    initial_guess,\n",
    "    bounds=[(0, 1), (0, 1), (0, 1)],\n",
    "    method='SLSQP')\n",
    "\n",
    "if result.success:\n",
    "    alpha_opt, beta_opt, theta_opt = result.x\n",
    "    gamma_opt = 1 - beta_opt\n",
    "    print(f\"Optimal alpha: {alpha_opt:.5f}\")\n",
    "    print(f\"Optimal beta: {beta_opt:.5f}\")\n",
    "    print(f\"Optimal gamma: {gamma_opt:.5f}\")\n",
    "    print(f\"Optimal theta: {theta_opt:.5f}\")\n",
    "else:\n",
    "    print(\"Optimization failed:\", result.message)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "y_norm_opt = (\n",
    "    alpha_opt +\n",
    "    beta_opt * (1 - n*alpha_opt - theta_opt) * model_data_no_journal[\"na_share\"] + \n",
    "    gamma_opt * (1 - n*alpha_opt - theta_opt) * model_data_no_journal[\"pres_votes_share\"] +\n",
    "    theta_opt * model_data_no_journal[\"government\"])\n",
    "\n",
    "r2 = r2_score(y, y_norm_opt)\n",
    "mr = mean_r(y, y_norm_opt)\n",
    "mrr = mean_rr(y, y_norm_opt)\n",
    "mape = mean_ape(y, y_norm_opt)\n",
    "rmspe = root_mse(y, y_norm_opt)\n",
    "\n",
    "print(f\"R2: {100*r2:.2f}%\")\n",
    "print(f\"MR: {100*mr:.2f}%\")\n",
    "print(f\"MRR: {100*mrr:.2f}%\")\n",
    "print(f\"MAPE: {100*mape:.2f}%\")\n",
    "print(f\"RMSPE: {rmspe:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81737fe",
   "metadata": {},
   "source": [
    "On obtient encore des résultats comparables si l'on restreint l'estimation au *Monde* avant juin 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f47a4-4abe-46e7-bb67-f3045b12bdb7",
   "metadata": {},
   "source": [
    "# 1. Ecarts à la norme de représentativité selon les nuances politiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bcea33-b9b2-4e5c-b6ed-e0b6bd812b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_no_journal['y_norm'] = (\n",
    "    alpha +\n",
    "    beta * (1 - n*alpha - theta) * model_data_no_journal[\"na_share\"] + \n",
    "    gamma * (1 - n*alpha - theta) * model_data_no_journal[\"pres_votes_share\"] +\n",
    "    theta * model_data_no_journal[\"government\"])\n",
    "model_data_no_journal['abs_residuals'] = 100 * (model_data_no_journal[outcome] - model_data_no_journal['y_norm'])\n",
    "model_data_no_journal['rel_residuals'] = 100 * (model_data_no_journal[outcome] - model_data_no_journal['y_norm']) / model_data_no_journal['y_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b83cc-69c2-4031-b455-94f56927c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_list = []\n",
    "\n",
    "for alignment in model_data_no_journal['political_alignment'].unique():\n",
    "    subset_data = model_data_no_journal[model_data_no_journal['political_alignment'] == alignment]\n",
    "    y = subset_data[outcome]\n",
    "    y_norm = subset_data['y_norm']\n",
    "    mr = mean_r(y, y_norm)\n",
    "    mrr = mean_rr(y, y_norm)\n",
    "    mape = mean_ape(y, y_norm)\n",
    "    rmspe = root_mse(y, y_norm)\n",
    "    summary_list.append({\n",
    "        'Political alignment': alignment,\n",
    "        'MR': mr,\n",
    "        'MRR': mrr,\n",
    "        'MAPE': mape,\n",
    "        'RMSPE': rmspe\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(summary_list)\n",
    "summary[\"Political alignment\"] = pd.Categorical(summary[\"Political alignment\"], categories=nuances_order, ordered=True)\n",
    "summary.style.hide(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa82bd2-57ad-427a-8de2-e7b32460e2b1",
   "metadata": {},
   "source": [
    "Dans quelle mesure les journalistes respectent-ils la norme de représentativité concernant différentes nuances politiques ?\n",
    "- Etroitement concernant la droite et la gauche (avec une MAPE plus élevée pour la gauche, mais des MRR quasi-nuls, montrant que les écarts à la norme se compensent en moyenne)\n",
    "- Moyennement concernant l'extrême droite et l'extrême gauche, avec des MAPE et des MRR entre 40 et 65 % en valeur absolue (mais des MRR de signes opposés, témoignant d'écarts à la norme favorables à l'extrême droite et défavorables à l'extrême gauche)\n",
    "- Faiblement pour le centre, avec une MAPE plus de 10 fois supérieure à celle de la droite (et des MRR positifs témoignant d'écarts favorables)\n",
    "\n",
    "Dans l'ensemble, la norme de représentativité semble davantage respectée pour les nuances politiques au pouvoir, c'est-à-dire essentiellement la droite et la gauche entre 1981 et 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a35bd-30cf-488c-8406-d4b7379ab74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff1 = pd.Period('2002-06', freq='M')\n",
    "cutoff2 = pd.Period('2017-06', freq='M')\n",
    "\n",
    "models = {}\n",
    "\n",
    "for period_label, period_filter in {\n",
    "    '1981-2002': model_data_no_journal[\"month\"] < cutoff1,\n",
    "    '2002-2017': (model_data_no_journal[\"month\"] >= cutoff1) & (model_data_no_journal[\"month\"] < cutoff2),\n",
    "    '2017-2024': model_data_no_journal[\"month\"] >= cutoff2\n",
    "}.items():\n",
    "    \n",
    "    models[period_label] = {}\n",
    "    period_data = model_data_no_journal[period_filter]\n",
    "    \n",
    "    for alignment in period_data[\"political_alignment\"].unique():\n",
    "        models[period_label][alignment] = {}\n",
    "        subset = period_data[period_data[\"political_alignment\"] == alignment]\n",
    "\n",
    "        if len(subset) >= 3:\n",
    "            y = subset[outcome]\n",
    "            y_norm = subset['y_norm']\n",
    "            mr = mean_r(y, y_norm)\n",
    "            mrr = mean_rr(y, y_norm)\n",
    "            mape = mean_ape(y, y_norm)\n",
    "            rmspe = root_mse(y, y_norm)\n",
    "\n",
    "            models[period_label][alignment] = {\n",
    "                \"MR\": mr,\n",
    "                \"MRR\": mrr,\n",
    "                \"MAPE\": mape,\n",
    "                \"RMSPE\": rmspe}\n",
    "\n",
    "        else:\n",
    "            models[period_label][alignment] = {\n",
    "                \"MR\": None,\n",
    "                \"MRR\": None,\n",
    "                \"MAPE\": None,\n",
    "                \"RMSPE\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86e399-22a8-400e-a773-a6235b7fe1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_list = []\n",
    "\n",
    "for period, alignment_dict in models.items():\n",
    "    for alignment, model_info in alignment_dict.items():\n",
    "        summary_list.append({\n",
    "            \"period\": period,\n",
    "            \"alignment\": alignment,\n",
    "            \"mr\": model_info[\"MR\"],\n",
    "            \"mrr\": model_info[\"MRR\"],\n",
    "            \"mape\": model_info[\"MAPE\"],\n",
    "            \"rmspe\": model_info[\"RMSPE\"]\n",
    "        })\n",
    "\n",
    "summary = pd.DataFrame(summary_list)\n",
    "summary[\"alignment\"] = pd.Categorical(summary[\"alignment\"], categories=nuances_order, ordered=True)\n",
    "summary = summary.pivot_table(index=\"alignment\",\n",
    "                                    columns=\"period\",\n",
    "                                    values=[\"mr\", \"mrr\"],\n",
    "                                    observed=False)\n",
    "summary = summary.reset_index()\n",
    "summary.columns.names = [None, None]\n",
    "summary.style.hide(axis=\"index\").format({col: \"{:.3f}\" for col in summary.columns[1:]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ae569-2abc-4c6c-8270-f8d1782e2c3a",
   "metadata": {},
   "source": [
    "Les évolutions temporelles des écarts à la norme de représentativité font apparaître un tableau plus complexe, notamment à cause de variations brutales concernant le centre et la gauche, témoignant d'une couverture médiatique qui leur serait massivement favorable, respectivement, en 2002-2017 et 2017-2024.\n",
    "\n",
    "La couverture de l'extrême droite est marquée par une convergence forte vers la norme de représentatitivé entre les deux premières périodes, avec des MAPE et des MRR divisés par 2 environ. Le traitement de cette nuance, d'abord favorable, serait ainsi devenu neutre.\n",
    "\n",
    "La couverture de l'extrême gauche est marquée par une légère convergence entre les deux dernières périodes, avec des MRR demeurant très négatifs, témoingnant d'un traitement défavorable.\n",
    "\n",
    "Quant à la droite, sa couverture demeure stable, au plus près de la norme de représentativité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3809e-3ba5-48d1-b377-de438df09429",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = model_data_no_journal.copy()\n",
    "plot_data['month'] = plot_data['month'].dt.to_timestamp()\n",
    "\n",
    "alignment_groups = [\n",
    "    (['Far left', 'Far right', 'Other'],\n",
    "     {'Far left': 'crimson',\n",
    "      'Far right': 'royalblue',\n",
    "      'Other': 'forestgreen'}),\n",
    "    (['Right', 'Left', 'Center'],\n",
    "     {'Right': 'cornflowerblue',\n",
    "      'Left': 'orchid',\n",
    "      'Center': 'goldenrod'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cb223-f9a5-45e6-9f74-182199d9ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alignment in ['Far right', 'Far left']:\n",
    "    color = 'royalblue' if alignment == 'Far right' else 'crimson'\n",
    "    subset_data = plot_data[plot_data['political_alignment'] == alignment].copy()\n",
    "    subset_data['MA_observed'] = subset_data[outcome].rolling(window=12).mean()\n",
    "    subset_data['MA_rel'] = subset_data['rel_residuals'].rolling(window=12).mean()\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(16, 10), sharex=True)\n",
    "\n",
    "    sns.lineplot(data=subset_data, x='month', y=outcome, ax=axes[0], label='Observed values', alpha=0.15, color=color, linestyle='-')\n",
    "    sns.lineplot(data=subset_data, x='month', y='MA_observed', ax=axes[0], label='12 months moving average for OV', color=color, linestyle='dashdot')\n",
    "    sns.lineplot(data=subset_data, x='month', y='y_norm', ax=axes[0], label='Predicted values', color='teal', linestyle='dotted')\n",
    "    axes[0].set_title(\"Observed and Predicted Values\")\n",
    "    axes[0].set_ylabel('')\n",
    "\n",
    "    sns.lineplot(data=subset_data, x='month', y='rel_residuals', ax=axes[1], label='Relative residuals', alpha=0.15, color=color, linestyle='-')\n",
    "    sns.lineplot(data=subset_data, x='month', y='MA_rel', ax=axes[1], label='12 months moving average for RR', color=color, linestyle='dashdot')\n",
    "    sns.lineplot(data=subset_data, x='month', y='y_norm', ax=axes[1], label='Predicted values', color='teal', linestyle='dotted')\n",
    "    axes[1].set_title(\"Relative Residuals (%)\")\n",
    "    axes[1].set_xlabel('')\n",
    "    axes[1].set_ylabel('')\n",
    "\n",
    "    add_shaded_periods(axes, main_elec_months, color='black', alpha=0.1)\n",
    "\n",
    "    plt.suptitle(f\"Proportion of Quotes Attributed to {alignment} Politicians\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"output/{alignment}_graph.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d45ccc-1243-4fbe-9780-c2d25da1e145",
   "metadata": {},
   "source": [
    "Concernant spécifiquement l'extrême droite, on n'observe pas d'augmentation tendancielle des résidus relatifs, qui témoignerait d'une application de plus en plus laxiste de la norme de représentativité, dans un sens favorable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f8652-b99f-4424-98c5-42ab1719a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12), sharex=True)\n",
    "\n",
    "for ax, (political_alignments, colors) in zip(axes, alignment_groups):\n",
    "    alignment_handles = []\n",
    "\n",
    "    for alignment in political_alignments:\n",
    "        subset_data = plot_data[plot_data['political_alignment'] == alignment].copy()\n",
    "        subset_data['MA'] = subset_data[outcome].rolling(window=6).mean()\n",
    "        \n",
    "        ax.plot(subset_data['month'], subset_data[outcome], label=None,\n",
    "                alpha=0.2, color=colors[alignment], linestyle='-')\n",
    "        ax.plot(subset_data['month'], subset_data['MA'], label=None,\n",
    "                alpha=0.65, color=colors[alignment], linestyle='dashdot')\n",
    "        ax.plot(subset_data['month'], subset_data['y_norm'], label=None,\n",
    "                alpha=1, color=colors[alignment], linestyle='dotted')\n",
    "        \n",
    "        alignment_handles.append(Line2D([0], [0], color=colors[alignment], lw=2, label=alignment))\n",
    "\n",
    "    alignment_legend = ax.legend(handles=alignment_handles, title=\"Political alignment\", loc=\"upper left\")\n",
    "    ax.add_artist(alignment_legend)\n",
    "\n",
    "    line_type_handles = [\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='-', label=\"Monthly average\"),\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='dashdot', label=\"6 months moving average\"),\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='dotted', label=\"Predictions\")]\n",
    "    ax.legend(handles=line_type_handles, title=\"Values\", loc=\"upper right\")\n",
    "\n",
    "axes[-1].set_xlabel(\"\")\n",
    "\n",
    "add_shaded_periods(axes, main_elec_months, color='black', alpha=0.1)\n",
    "\n",
    "plt.suptitle(\"Quote Distribution by Political Affiliation\\nObserved vs. Predicted Values\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/nuances_val_graph.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042da6c0-ab69-4b3c-ae62-1e61f994b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12), sharex=True)\n",
    "\n",
    "for ax, (political_alignments, colors) in zip(axes, alignment_groups):\n",
    "    alignment_handles = []\n",
    "\n",
    "    for alignment in political_alignments:\n",
    "        subset_data = plot_data[plot_data['political_alignment'] == alignment].copy()\n",
    "        subset_data['MA'] = subset_data['rel_residuals'].rolling(window=6).mean()\n",
    "        \n",
    "        ax.plot(subset_data['month'], subset_data['rel_residuals'], label=None,\n",
    "                alpha=0.2, color=colors[alignment], linestyle='-')\n",
    "        ax.plot(subset_data['month'], subset_data['MA'], label=None,\n",
    "                alpha=0.65, color=colors[alignment], linestyle='-.')\n",
    "        ax.plot(subset_data['month'], [0] * len(subset_data), label=None,\n",
    "                alpha=1, color='darkgray', linestyle=':')\n",
    "        \n",
    "        alignment_handles.append(Line2D([0], [0], color=colors[alignment], lw=2, label=alignment))\n",
    "\n",
    "    alignment_legend = ax.legend(handles=alignment_handles, title=\"Political alignment\", loc=\"upper left\")\n",
    "    ax.add_artist(alignment_legend)\n",
    "\n",
    "    line_type_handles = [\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='-', label=\"Monthly average\"),\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='-.', label=\"6 months moving average\"),\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle=':', label=\"Predictions\")\n",
    "    ]\n",
    "    ax.legend(handles=line_type_handles, title=\"Values\", loc=\"upper right\")\n",
    "\n",
    "axes[-1].set_xlabel(\"\")\n",
    "\n",
    "add_shaded_periods(axes, main_elec_months, color='black', alpha=0.1)\n",
    "\n",
    "plt.suptitle(\"Quote Distribution by Political Affiliation\\nRelative Residuals (%)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/nuances_res_graph.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac606c34-6e6a-421e-a7bf-ea1a8c3725e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12), sharex=True)\n",
    "\n",
    "for ax, (political_alignments, colors) in zip(axes, alignment_groups):\n",
    "    alignment_handles = []\n",
    "\n",
    "    for alignment in political_alignments:\n",
    "        subset_data = plot_data[plot_data['political_alignment'] == alignment].copy()\n",
    "        subset_data['MA'] = subset_data['abs_residuals'].rolling(window=6).mean()\n",
    "        \n",
    "        ax.plot(subset_data['month'], subset_data['abs_residuals'], label=None,\n",
    "                alpha=0.2, color=colors[alignment], linestyle='-')\n",
    "        ax.plot(subset_data['month'], subset_data['MA'], label=None,\n",
    "                alpha=0.65, color=colors[alignment], linestyle='-.')\n",
    "        ax.plot(subset_data['month'], [0] * len(subset_data), label=None,\n",
    "                alpha=1, color='darkgray', linestyle=':')\n",
    "        \n",
    "        alignment_handles.append(Line2D([0], [0], color=colors[alignment], lw=2, label=alignment))\n",
    "\n",
    "    alignment_legend = ax.legend(handles=alignment_handles, title=\"Political alignment\", loc=\"upper left\")\n",
    "    ax.add_artist(alignment_legend)\n",
    "\n",
    "    line_type_handles = [\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='-', label=\"Monthly average\"),\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle='-.', label=\"6 months moving average\"),\n",
    "        Line2D([0], [0], color='black', lw=2, linestyle=':', label=\"Predictions\")\n",
    "    ]\n",
    "    ax.legend(handles=line_type_handles, title=\"Values\", loc=\"upper right\")\n",
    "\n",
    "axes[-1].set_xlabel(\"\")\n",
    "\n",
    "add_shaded_periods(axes, main_elec_months, color='black', alpha=0.1)\n",
    "\n",
    "plt.suptitle(\"Quote Distribution by Political Affiliation\\nAbsolute Residuals (%)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/nuances_abs_graph.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3793999-343e-4856-b60f-dc18e75693e5",
   "metadata": {},
   "source": [
    "Le résultat le plus flagrant est la présence de deux dynamiques non-capturées : \n",
    "- L'une pour l'extrême-droite entre 1983 et 1985. L'année 1984 correspond au premier succès du Front national lors d'une élection nationale. Or, il s'agit des européennes, dont les résultats ne sont pas intégrés notre modèle normatif. Lorsque l'on exclut la période correspondante, les MAPE du modèle *a priori* deviennent équivalente pour l'extrême droite et l'extrême gauche (mais avec des MRR toujours bien plus négatifs pour la seconde) (cf. *infra*).\n",
    "- L'autre pour le centre entre 2007 et 2017. Ici, le décalage entre les comportements réels et prescrits est plus difficilement explicable. L'année 2007 est marquée par la percée de François Bayrou lors des élections présidentielles, qui arrive 3e avec 18,57 % des voix, et l'année 2017 par la victoire d'Emmanuel Macron à ces mêmes élections. Mais les résultats de ces dernières sont bien pris en compte par notre modèle normatif. Alors... ? Observons nous ici un fort engagement des rédactions en faveur du centre ? Ou cette impression résulte-t-elle de problèmes dans les données ?\n",
    "\n",
    "On constate aussi l'existence d'une prime à la majorité pour les partis accédant au pouvoir, qui reçoivent toujours davantage de citations que prescrit pas notre modèle. Mais curieusement, l'ajout de la nuance politique du Premier ministre aux modèles estimés n'améliore pas leurs performances prédictives (cf. *infra*).\n",
    "\n",
    "Enfin, aucun biais systématique n'apparaît dans la couverture médiatique des nuances politiques, sauf en défaveur de l'extrême gauche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e6975-9493-4a1e-b2e6-af590f187c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_list = []\n",
    "\n",
    "for alignment in model_data_no_journal['political_alignment'].unique():\n",
    "    subset_data = model_data_no_journal[(model_data_no_journal['political_alignment'] == alignment) & (model_data_no_journal[\"month\"] > pd.Period('1988-01', freq='M'))]\n",
    "    y = subset_data[outcome]\n",
    "    y_norm = subset_data['y_norm']\n",
    "    mr = mean_r(y, y_norm)\n",
    "    mrr = mean_rr(y, y_norm)\n",
    "    mape = mean_ape(y, y_norm)\n",
    "    rmspe = root_mse(y, y_norm)\n",
    "    summary_list.append({\n",
    "        'Political alignment': alignment,\n",
    "        'MR': mr,\n",
    "        'MRR': mrr,\n",
    "        'MAPE': mape,\n",
    "        'RMSPE': rmspe\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(summary_list)\n",
    "summary[\"Political alignment\"] = pd.Categorical(summary[\"Political alignment\"], categories=nuances_order, ordered=True)\n",
    "summary.style.hide(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a45e48-7b0d-4ed3-94e3-594c3b778628",
   "metadata": {},
   "source": [
    "*Tentative pour calculer la proportion des proportions de citations correctement prescrites...*\n",
    "- *Correct prescriptions = proportion des citations prescrites correspondant à des citations réelles*\n",
    "- *Excess prescriptions = proportion des citations prescrites excédant les citations réelles*\n",
    "- *True missing = proportion des citations réelles non-prescrites par le modèle a priori*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba858676-d022-441e-96fd-8db7ca8f0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_proportional_metrics(y_norm, y_true):\n",
    "    y_norm = np.array(y_norm)\n",
    "    y_true = np.array(y_true)\n",
    "    \n",
    "    # Initialize arrays\n",
    "    TP = np.zeros_like(y_norm)\n",
    "    TN = np.zeros_like(y_norm)\n",
    "    FP = np.zeros_like(y_norm)\n",
    "    FN = np.zeros_like(y_norm)\n",
    "    \n",
    "    # Calculate difference\n",
    "    diff = y_norm - y_true\n",
    "    \n",
    "    # Case 1: y_norm - y_true = 0 (perfect prediction)\n",
    "    perfect_mask = (diff == 0)\n",
    "    TP[perfect_mask] = 1\n",
    "    FP[perfect_mask] = 0\n",
    "    FN[perfect_mask] = 0\n",
    "    \n",
    "    # Case 2: y_norm - y_true > 0 (over-prediction)\n",
    "    over_mask = (diff > 0)\n",
    "    TP[over_mask] = y_true[over_mask] / y_norm[over_mask]\n",
    "    FP[over_mask] = diff[over_mask] / y_norm[over_mask]\n",
    "    FN[over_mask] = 0\n",
    "    \n",
    "    # Case 3: y_norm - y_true < 0 (under-prediction)\n",
    "    under_mask = (diff < 0)\n",
    "    TP[under_mask] = 1\n",
    "    FN[under_mask] = - diff[under_mask] / y_true[under_mask]\n",
    "    FP[under_mask] = 0\n",
    "    \n",
    "    return {\n",
    "        'TP': TP.mean(),\n",
    "        'FP': FP.mean(),\n",
    "        'FN': FN.mean()}\n",
    "\n",
    "summary_list = []\n",
    "\n",
    "for alignment in model_data_no_journal['political_alignment'].unique():\n",
    "    subset_data = model_data_no_journal[model_data_no_journal['political_alignment'] == alignment]\n",
    "    y = subset_data[outcome]\n",
    "    y_norm = subset_data['y_norm']\n",
    "    metrics = compute_proportional_metrics(y_norm, y)\n",
    "    summary_list.append({\n",
    "        'Political alignment': alignment,\n",
    "        '% correct prescriptions': 100 * metrics['TP'],\n",
    "        '% excess prescriptions': 100 * metrics['FP'],\n",
    "        '% missing prescriptions': 100 * metrics['FN']})\n",
    "\n",
    "summary = pd.DataFrame(summary_list)\n",
    "summary[\"Political alignment\"] = pd.Categorical(summary[\"Political alignment\"], categories=nuances_order, ordered=True)\n",
    "summary.style.hide(axis=\"index\").format({col: \"{:.2f}\" for col in summary.columns[1:]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d2dfa-8ce0-4880-b0a0-b88660995b2f",
   "metadata": {},
   "source": [
    "# 2. Ecarts à la norme de représentativité selon les journaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621e895-c175-4179-b23b-08c624b6ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data['y_norm'] = y_norm = (\n",
    "    alpha +\n",
    "    beta * (1 - n*alpha - theta) * model_data[\"na_share\"] + \n",
    "    gamma * (1 - n*alpha - theta) * model_data[\"pres_votes_share\"] +\n",
    "    theta * model_data[\"government\"])\n",
    "model_data['abs_residuals'] = 100 * (model_data[outcome] - model_data['y_norm'])\n",
    "model_data['rel_residuals'] = 100 * (model_data[outcome] - model_data['y_norm']) / model_data['y_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6ccd2-e339-4c3c-8970-07d4442c3125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = []\n",
    "\n",
    "for journal in model_data['journal'].unique():\n",
    "    subset_data = model_data[model_data['journal'] == journal]\n",
    "    y = subset_data[outcome]\n",
    "    y_norm = subset_data['y_norm']\n",
    "    mr = mean_r(y, y_norm)\n",
    "    mrr = mean_rr(y, y_norm)\n",
    "    mape = mean_ape(y, y_norm)\n",
    "    rmspe = root_mse(y, y_norm) / y.mean()\n",
    "    summary.append({\n",
    "        'Journal': journal,\n",
    "        'MR': mr,\n",
    "        'MRR': mrr,\n",
    "        'MAPE': mape,\n",
    "        'RMSPE': rmspe})\n",
    "\n",
    "pd.DataFrame(summary).style.hide(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2dbd8c-65b1-48e5-9993-fdd652baf22e",
   "metadata": {},
   "source": [
    "Trois groupes de journaux apparaissent :\n",
    "- Le Figaro et Le Monde respectent le plus la norme de représentativité\n",
    "- La Croix et Libération la respectent un peu moins\n",
    "- Médiapart s'en écarte plus franchement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562abef-16c0-4231-a1f0-c43e6a8563c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for journal in model_data['journal'].unique():\n",
    "    for alignment in model_data['political_alignment'].unique():\n",
    "        subset_data = model_data[(model_data['journal'] == journal) & (model_data['political_alignment'] == alignment)]\n",
    "        y = subset_data[outcome]\n",
    "        y_norm = subset_data['y_norm']\n",
    "        mr = mean_r(y, y_norm)\n",
    "        mrr = mean_rr(y, y_norm)\n",
    "        mape = mean_ape(y, y_norm)\n",
    "        rmspe = root_mse(y, y_norm)\n",
    "        results.append({\n",
    "            'alignment': alignment,\n",
    "            'journal': journal,\n",
    "            'MR': mr,\n",
    "            'MRR': mrr,\n",
    "            'MAPE': mape,\n",
    "            'RMSPE': rmspe})\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results[\"alignment\"] = pd.Categorical(results[\"alignment\"], categories=nuances_order, ordered=True)\n",
    "results = results.sort_values([\"alignment\", \"journal\"])\n",
    "results = results.set_index([\"alignment\", \"journal\"])\n",
    "results.index.names = [\"Political Alignment\", \"Journal\"]\n",
    "\n",
    "results.style.format(\"{:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16715620-3946-4c60-9291-2e335005df78",
   "metadata": {},
   "source": [
    "Le traitement du centre par La Croix et de la gauche par Libération semble responsable de leur déviation supérieure par rapport au Monde et au Figaro. Médiapart se distingue en citant davantage l'extrême gauche, mais plus encore l'extrême droite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6321ae5-94fd-4518-8a0a-1d177a3e9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = model_data.copy()\n",
    "plot_data['month'] = plot_data['month'].dt.to_timestamp()\n",
    "\n",
    "colors = {\n",
    "    'Le Figaro': 'goldenrod',\n",
    "    'Libération': 'limegreen',\n",
    "    'Le Monde': 'orchid',\n",
    "    'La Croix': 'skyblue',\n",
    "    'Médiapart': 'crimson'}\n",
    "\n",
    "alignments = [\n",
    "    \"Far right\",\n",
    "    \"Right\",\n",
    "    \"Center\",\n",
    "    \"Left\",\n",
    "    \"Far left\"]\n",
    "\n",
    "n_alignments = len(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7479b96-184e-4ed0-9528-39c29b3767a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(n_alignments, 1, figsize=(16, 4 * n_alignments), sharex=True)\n",
    "\n",
    "for i, alignment in enumerate(alignments):\n",
    "    ax = axes[i]\n",
    "    subset_data = plot_data[plot_data['political_alignment'] == alignment]\n",
    "\n",
    "    for journal in subset_data['journal'].unique():\n",
    "        if journal == 'Médiapart': continue\n",
    "        sub_subset_data = subset_data[subset_data['journal'] == journal].copy()\n",
    "        sub_subset_data['MA'] = sub_subset_data[outcome].rolling(window=12).mean()\n",
    "        ax.plot(sub_subset_data['month'], sub_subset_data[outcome], label=journal,\n",
    "                alpha=0.7, color=colors[journal], linestyle='-')\n",
    "\n",
    "    ax.plot(subset_data['month'], subset_data['y_norm'], color='black', alpha=0.8, linestyle='dotted')\n",
    "    ax.set_title(f\"{alignment}\")\n",
    "    ax.legend()\n",
    "\n",
    "add_shaded_periods(axes, main_elec_months, color='black', alpha=0.1)\n",
    "\n",
    "plt.suptitle(\"\"\"\n",
    "Quote Distribution by Political Affiliation and Journal\\n\n",
    "Observed vs. Predicted Values\n",
    "\"\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/journals_val_graph.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0704e63-4bdd-4fb2-a640-4e435e2bd354",
   "metadata": {},
   "source": [
    "Médiapart est exclu des graphs car ses données semblent assez erratiques jusqu'en 2012 : le nombre d'articles publiés est probablement faible, ce qui conduit à atteindre régulièrement des proportions de 1 pour certaines nuances politiques.\n",
    "\n",
    "On retrouve de manière plus visible que dans le tableau les différences éditoriales auxquelles on pouvait s'attendre : le Figaro et la Croix couvrent davantage la droite que le Monde et Libération, et inversement pour la gauche et l'extrême gauche. Concernant l'extrême droite, aucune différence flagrante n'apparaît."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920d2f4-2e7e-4aa5-b57b-5122463da028",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(n_alignments, 1, figsize=(16, 4 * n_alignments), sharex=True)\n",
    "\n",
    "for i, alignment in enumerate(alignments):\n",
    "    ax = axes[i]\n",
    "    subset_data = plot_data[plot_data['political_alignment'] == alignment]\n",
    "\n",
    "    for journal in subset_data['journal'].unique():\n",
    "        sub_subset_data = subset_data[subset_data['journal'] == journal].copy()\n",
    "        sub_subset_data['MA'] = sub_subset_data['rel_residuals'].rolling(window=12).mean()\n",
    "        ax.plot(sub_subset_data['month'], sub_subset_data['MA'], label=journal,\n",
    "                alpha=0.7, color=colors[journal], linestyle='-')\n",
    "\n",
    "    ax.plot(subset_data['month'], subset_data['y_norm'], color='black', alpha=0.8, linestyle='dotted')\n",
    "    ax.set_title(f\"{alignment}\")\n",
    "    ax.legend()\n",
    "\n",
    "add_shaded_periods(axes, main_elec_months, color='black', alpha=0.1)\n",
    "\n",
    "plt.suptitle(\"\"\"\n",
    "Quote Distribution by Political Affiliation and Journal\\n\n",
    "Relative Residuals (%) - 12 months moving averages\n",
    "\"\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/journals_res_graph.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ade65-e0f9-463e-ae4a-ee53aa238f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vérifications...\n",
    "model_data_no_journal[model_data_no_journal['political_alignment'] == 'Far right'][['month', 'quotes_share', 'y_norm', 'rel_residuals']].head(n=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d64103f",
   "metadata": {},
   "source": [
    "# 3. Work in progress / Régression des résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e1fd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = smf.ols(f\"abs_residuals ~ political_alignment - 1\", \n",
    "                data=model_data_no_journal).fit(cov_type='HC3')\n",
    "\n",
    "y = model_data_no_journal[outcome]\n",
    "y_pred = model.predict(model_data_no_journal)\n",
    "y_norm = model_data_no_journal['y_norm']\n",
    "\n",
    "r2 = r2_score(y_norm, y_pred)\n",
    "print(f\"R2: {100*r2:.2f}%\")\n",
    "\n",
    "params = model.params.rename(\"coef\").to_frame()\n",
    "pvalues = model.pvalues.rename(\"pval\").to_frame()\n",
    "results = pd.merge(params, pvalues, left_index=True, right_index=True)\n",
    "results = results[results['pval'] <= 0.1]\n",
    "results.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(model_data_no_journal['political_alignment'], prefix='alignment')\n",
    "X = X.drop(columns='alignment_Other')\n",
    "X = X.astype(float)\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y_norm, X).fit(cov_type='HC3')\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "r2 = r2_score(y_norm, y_pred)\n",
    "print(f\"R2: {100*r2:.2f}%\")\n",
    "\n",
    "params = model.params.rename(\"coef\").to_frame()\n",
    "pvalues = model.pvalues.rename(\"pval\").to_frame()\n",
    "results = pd.merge(params, pvalues, left_index=True, right_index=True)\n",
    "results = results[results['pval'] <= 0.1]\n",
    "results.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6344abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mais revient juste à calculer la moyenne des résidus par orientation politique (en l'absence de constante)\n",
    "model_data_no_journal['y_norm'] = y_norm\n",
    "model_data_no_journal[model_data_no_journal['political_alignment'] == \"Center\"]['y_norm'].mean()\n",
    "# ou en la moyenne des résidus retranchée par orientation retranchée de la moyenne globale des résidus (en présence d'une constante) ?\n",
    "# Pas exactement semble-t-il...\n",
    "model_data_no_journal[model_data_no_journal['political_alignment'] == \"Center\"]['y_norm'].mean() - (y-y_norm).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
